{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the past, United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the United States, 112 commercial nuclear reactors have operated since 1967. Published data of these reactors is used in _CYCLUS_, an agent-based simulation software, in order to compare simulation results with real world metrics and produce  baseline comparison models for future simulations. Information regarding reactors are obtained from Power Reactor Information System's (PRIS) reactor database. [reactors_pris_2016.csv](import_data/reactors_pris_2016.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Recipes for Simulation\n",
    "\n",
    "First, an input file for _CYCLUS_ specifying the recipes for fresh and spent nuclear fuel (SNF) is produced. The recipes for fresh and SNF are obtained from `vision_recipes.xls` spreadsheet file, which contains isotopes and compositions for fresh and SNF for uranium oxide (UOX) and mixed oxide (MOX) fuel at different burn ups.\n",
    "\n",
    "Importing raw composition data from `vision_recipes.xls` is performed with a python script and is demonstrated below. Due to limited information about the reactors, all reactors are assumed to operate at a burn up of 51 GWd/MTHM.\n",
    "\n",
    "### Demonstration\n",
    "__Import necessary libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.732663Z",
     "start_time": "2017-11-29T04:01:52.346957Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import dateutil.parser as date\n",
    "import import_fleetcomp as idata\n",
    "import jinja2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import sqlite3 as lite\n",
    "from matplotlib import cm\n",
    "from pyne import nucname as nn\n",
    "from IPython.display import Image\n",
    "\n",
    "sys.path.append('analysis/')\n",
    "import analysis as an\n",
    "\n",
    "region = 'united_states'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read fuel recipe data__\n",
    "\n",
    "`vision_recipes.xls` is stored to a list object by looping over each row in the spreadsheet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.749601Z",
     "start_time": "2017-11-29T04:01:52.734645Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He4', '0', '2.09687731425456E-07', '0', '9.47457840128509E-07', '0', '2.0692755421168E-06', '0']\n",
      "['Ra226', '0', '1.18893043712383E-14', '0', '9.78856442957042E-14', '0', '0', '0']\n",
      "['Ra228', '0', '6.05164592554536E-21', '0', '2.75087759176098E-20', '0', '6.0138599011451E-20', '0']\n",
      "['Pb206', '0', '7.66855132237399E-20', '0', '5.57475193532078E-18', '0', '1.40345550165974E-17', '0']\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "def import_csv(in_csv, delimit):\n",
    "    \"\"\" Imports contents of a comma delimited csv file\n",
    "    to a 2D list.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_csv: str\n",
    "        csv file name.\n",
    "    delimit: str\n",
    "        delimiter of the csv file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_list: list\n",
    "        list with fleetcomp data.\n",
    "    \"\"\"\n",
    "    with open(in_csv, encoding='utf-8') as source:\n",
    "        sourcereader = csv.reader(source, delimiter=delimit)\n",
    "        data_list = []\n",
    "        for row in sourcereader:\n",
    "            data_list.append(row)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "recipes = import_csv('import_data/vision_recipes/uox.csv', ',')\n",
    "print(*recipes[2:6], '.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load template for _CYCLUS_ input file__\n",
    "\n",
    "A jinja template file, used to produce parts of the final _CYCLUS_ simulation input file, is loaded to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.776225Z",
     "start_time": "2017-11-29T04:01:52.751262Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_template(in_template):\n",
    "    \"\"\" Returns a jinja2 template.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_template: str\n",
    "        template file name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_template: jinja template object\n",
    "    \"\"\"\n",
    "    with open(in_template, 'r') as default:\n",
    "        output_template = jinja2.Template(default.read())\n",
    "    return output_template\n",
    "\n",
    "\n",
    "recipe_template = load_template('templates/recipes_template.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select appropriate recipe for a given burnup__\n",
    "\n",
    "The appropriate composition for fresh and spent nuclear fuel is selected by specifying burnup. The composition data is then stored into a dictionary object with {isotope: mass fraction composition} as {key : value} pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.869248Z",
     "start_time": "2017-11-29T04:01:52.778210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent Fuel Composition:\n",
      "ISOTOPE:   Massfrac\n",
      "20040000 :  9.47457840128509e-07\n",
      "882260000 :  9.78856442957042e-14\n",
      "882280000 :  2.75087759176098e-20\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "def get_composition_fresh(in_list, burnup):\n",
    "    \"\"\" Returns a dictionary of isotope and composition (in mass fraction)\n",
    "    using vision_recipes for fresh UOX\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_list: list\n",
    "        list file containing vision_recipes data.\n",
    "    burnup: int\n",
    "        burnup\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_dict: dictionary\n",
    "        dictionary with key: isotope, and value: composition.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    for i in range(len(in_list)):\n",
    "        if i > 1:\n",
    "            if burnup == 33:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][1])})\n",
    "            elif burnup == 51:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][3])})\n",
    "            else:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][5])})\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def get_composition_spent(in_list, burnup):\n",
    "    \"\"\" Returns a dictionary of isotope and composition (in mass fraction)\n",
    "    using vision_recipes for spent nuclear fuel\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_list: list\n",
    "        list file containing vision_recipes data.\n",
    "    burnup: int\n",
    "        burnup\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_dict: dictionary\n",
    "        dictionary with key: isotope, and value: composition.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    for i in range(len(in_list)):\n",
    "        if i > 1:\n",
    "            if burnup == 33:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][2])})\n",
    "            elif burnup == 51:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][4])})\n",
    "            else:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][6])})\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "fresh = get_composition_fresh(recipes, 51)\n",
    "spent = get_composition_spent(recipes, 51)\n",
    "print('Spent Fuel Composition:')\n",
    "print('ISOTOPE:   Massfrac')\n",
    "for k in list(spent.keys())[:3]:\n",
    "    print(k, ': ', spent[k])\n",
    "print('.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Render recipe template with recipe data__\n",
    "\n",
    "`jinja2` library is used to render recipe data to the previously loaded `recipe_template`. `pyne` library is used to convert the isotope names to _CYCLUS_ readable format. The rendered information is then saved to an xml file for use with _CYCLUS_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.891348Z",
     "start_time": "2017-11-29T04:01:52.871917Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_recipes(fresh_dict, spent_dict, in_template, burnup, region):\n",
    "    \"\"\" Renders jinja template using fresh and spent fuel composition and\n",
    "    outputs an xml file containing recipe data\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    fresh_dict: dictionary\n",
    "        dictionary with key=isotope, and value=composition for fresh UOX\n",
    "    spent_dict: dictionary\n",
    "        dictionary with key=isotope, and value=composition for spent fuel\n",
    "    in_template: jinja template object\n",
    "        jinja template object to be rendered.\n",
    "    burnup: int\n",
    "        amount of burnup\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    null\n",
    "        generates reactor files for cyclus.\n",
    "    \"\"\"\n",
    "    out_path = 'cyclus/input/' + region + '/recipes/'\n",
    "    pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    rendered = in_template.render(fresh=fresh_dict,\n",
    "                                  spent=spent_dict)\n",
    "    with open(out_path + '/uox_' +\n",
    "              str(burnup) + '.xml', 'w') as output:\n",
    "        output.write(rendered)\n",
    "\n",
    "\n",
    "write_recipes(fresh, spent, recipe_template, 33, region)\n",
    "write_recipes(fresh, spent, recipe_template, 51, region)\n",
    "write_recipes(fresh, spent, recipe_template, 100, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[uox_51.xml](cyclus/input/US/recipes/uox_51.xml) is a sample rendered result that contains fresh and spent nuclear fuel compositions. \n",
    "\n",
    "__recipe template__\n",
    "\n",
    "`jinja2` library is used to produce various parts of the final  _CYCLUS_ input file using templates. The library replaces simulation-specific information, such as the recipe for SNF, from the specified template file. This allows end-users to produce _CYCLUS_ simulation inputs that vary depending on the data with which they have been rendered. An example is shown below.\n",
    "\n",
    "Recipe template file:\n",
    "\n",
    "```\n",
    "    <recipes>\n",
    "      <recipe>\n",
    "        <name>fresh_uox</name>\n",
    "        <basis>atom</basis>\n",
    "        <nuclide>\n",
    "          <id>922350000</id>\n",
    "          <comp>4.5</comp>\n",
    "        </nuclide>\n",
    "        <nuclide>\n",
    "          <id>922380000</id>\n",
    "          <comp>95.5</comp>\n",
    "        </nuclide>\n",
    "      </recipe>\n",
    "      <recipe>\n",
    "        <name>spent_uox</name>\n",
    "        <basis>atom</basis>\n",
    "        {% for key, value in vision.items() -%}\n",
    "        <nuclide>  <id>{{ key }}</id>  <comp>{{ value }}</comp>  </nuclide>\n",
    "        {% endfor -%}\n",
    "      </recipe>\n",
    "    </recipes>\n",
    "```\n",
    "\n",
    "The template shown above is a recipe template. `jinja2` recognizes variables within the brackets (`{{ }}`) and replaces the variables with appropriate values. The library also recognizes loops to produce multiple lines of text from a list of data. For instance, `jinja2` used the for-loop in the following lines\n",
    "```\n",
    "    {% for key, value in vision.items() -%}`\n",
    "    <nuclide>  <id>{{ key }}</id>  <comp>{{ value }}</comp>  </nuclide>\n",
    "    {% endfor -%}\n",
    "```\n",
    "and iterated over the composition dictionary to render the isotope and its composition.\n",
    "\n",
    "[uox_51.xml](cyclus/input/US/recipes/uox_51.xml) is the rendered result. \n",
    "\n",
    "## Obtaining Deployment Data\n",
    "\n",
    "Reactors specified in [reactors_pris_2016.csv](import_data/reactors_pris_2016.csv), need to be properly imported. The reactors should be deployed at the correct timesteps for an accurate simulation. The spreadsheet file contains reactor information including the name, deployment date, net capacity, and deployment nation. Obtaining reactor information for _CYCLUS_ is performed using a set of python functions. The same generic steps were repeated for this demonstration: importing data stored in a delimited text file, and rendering the imported data to a _CYCLUS_ template file using `jinja2`.\n",
    "\n",
    "### Demonstration\n",
    "__Read fleetcomp reactor data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.903340Z",
     "start_time": "2017-11-29T04:01:52.893789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argentina', 'ATUCHA-1', 'PHWR', '335', 'Operational', 'NASA', '6/1/1968', '1968', '1/13/1974', '3/19/1974', '6/24/1974', '', '83.1']\n",
      "['Argentina', 'EMBALSE', 'PHWR', '600', 'Operational', 'NASA', '4/1/1974', '1974', '3/13/1983', '4/25/1983', '1/20/1984', '', '69.6']\n",
      "['Argentina', 'ATUCHA-2', 'PHWR', '692', 'Operational', 'NASA', '7/14/1981', '1981', '6/3/2014', '6/27/2014', '', '', '0']\n",
      "['Argentina', 'CAREM25', 'PWR', '25', 'Under Construction', 'CNEA', '2/8/2014', '2014', '', '', '', '', '']\n",
      "['Bangladesh', 'Rooppur Nuclear Power Plant (Unit-I)', 'VVER', '1000-1250', 'Planned', '', '2016', '', '', '', '2021', '', '']\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "pris = import_csv('import_data/reactors_pris_2016.csv', ',')\n",
    "\n",
    "print(*pris[1:6], sep='\\n')\n",
    "print('.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select reactors in the specified region__\n",
    "\n",
    "PRIS reactor spreadsheet file contains information about nuclear reactors from various nations. In order to obtain commercial reactors deployed in the United States, a separate function was written that searches for reactors from the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.958978Z",
     "start_time": "2017-11-29T04:01:52.905315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States', 'SHIPPINGPORT', 'PWR', '60', 'Permanent Shutdown', 'DOE DUQU', '1/1/1954', '1954', '1/1/1957', '12/2/1957', '5/26/1958', '10/1/1982', '']\n",
      "['United States', 'GE VALLECITOS', 'BWR', '24', 'Permanent Shutdown', 'GE', '1/1/1956', '1956', '8/3/1957', '10/19/1957', '10/19/1957', '12/9/1963', '']\n",
      "['United States', 'DRESDEN-1', 'BWR', '197', 'Permanent Shutdown', 'EXELON', '5/1/1956', '1956', '10/15/1959', '4/15/1960', '7/4/1960', '10/31/1978', '']\n",
      "['United States', 'INDIAN POINT-1', 'PWR', '257', 'Permanent Shutdown', 'ENTERGY', '5/1/1956', '1956', '8/2/1962', '9/16/1962', '10/1/1962', '10/31/1974', '']\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "def select_region(in_list, region):\n",
    "    \"\"\" Returns a list of reactors that have a start_date\n",
    "    and are note experimental\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "            imported csv file in list format\n",
    "    region: str\n",
    "            name of the region\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    reactor_list: list\n",
    "            list of reactors from PRIS\n",
    "    \"\"\"\n",
    "    UNITED_STATES = {'UNITED STATES'}\n",
    "    SOUTH_AMERICA = {'ARGENTINA', 'BRAZIL'}\n",
    "    NORTH_AMERICA = {'CANADA', 'MEXICO', 'UNITED STATES'}\n",
    "    EUROPE = {'BELARUS', 'BELGIUM', 'BULGARIA',\n",
    "              'CZECHOSLOVAKIA', 'FINLAND', 'FRANCE',\n",
    "              'GERMANY', 'ITALY', 'NETHERLANDS',\n",
    "              'POLAND', 'ROMANIA', 'RUSSIA',\n",
    "              'SLOVENIA', 'SOVIET UNION', 'SPAIN',\n",
    "              'SWEDEN', 'SWITZERLAND', 'TURKEY',\n",
    "              'UKRAINE', 'UNITED KINGDOM'\n",
    "              }\n",
    "    ASIA = {'BANGLADESH', 'CHINA', 'INDIA',\n",
    "            'IRAN', 'JAPAN', 'KAZAKHSTAN',\n",
    "            'PAKISTAN', 'PHILIPPINES', 'SOUTH KOREA',\n",
    "            'UNITED ARAB EMIRATES', 'VIETNAM'}\n",
    "    AFRICA = {'EGYPT', 'MOROCCO', 'SOUTH AFRICA', 'TUNISIA'}\n",
    "    ALL = SOUTH_AMERICA | NORTH_AMERICA | EUROPE | ASIA | AFRICA | UNITED_STATES\n",
    "    regions = {'SOUTH_AMERICA': SOUTH_AMERICA, 'NORTH_AMERICA': NORTH_AMERICA,\n",
    "               'ASIA': ASIA, 'AFRICA': AFRICA, 'EUROPE': EUROPE, \n",
    "               'UNITED_STATES': UNITED_STATES, 'ALL': ALL}\n",
    "\n",
    "    if region.upper() not in regions.keys():\n",
    "        raise ValueError(region + 'is not a valid region')\n",
    "    reactor_list = []\n",
    "    for row in in_list:\n",
    "        country = row[0]\n",
    "        if country.upper() in regions[region.upper()]:\n",
    "            start_date = row[9]\n",
    "            if start_date.strip():\n",
    "                reactor_list.append(row)\n",
    "    return reactor_list\n",
    "\n",
    "reactor_list = select_region(pris, region)\n",
    "print(*reactor_list[:4], '.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select and render useful reactor information__\n",
    "\n",
    "In this step, the following information is obtained from the PRIS spreadsheet: reactor name, type, deployed nation, and capacity. Reactor specifications such as number of assemblies, assemblies per batch, mass of core, and mass of assembly were obtained from published sources [1], [2]. Then, `write_reactors` function is used to render these information. The function loops over each row and checks the type of reactor and its capacity. Reactors with capacity less than 400 MWe were assumed to be experimental reactors. Then, all the raw and derived variables necessary for simulation are rendered to individual reactor files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:53.244829Z",
     "start_time": "2017-11-29T04:01:52.961349Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_reactors(in_list, out_path, reactor_template):\n",
    "    \"\"\" Obtains information regarding reactors\n",
    "    and renders the information into a jinja template\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        list containing PRIS data\n",
    "    out_path: str\n",
    "        output path for reactor files\n",
    "    reactor_template: str\n",
    "        path to reactor template\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    null\n",
    "        writes xml files containing information about a reactor\n",
    "    \"\"\"\n",
    "    if out_path[-1] != '/':\n",
    "        out_path += '/'\n",
    "    pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    reactor_template = idata.load_template(reactor_template)\n",
    "    for row in in_list:\n",
    "        capacity = float(row[3])\n",
    "        if capacity >= 400:\n",
    "            name = row[1].replace(' ', '_').lower()\n",
    "            assem_per_batch = 0\n",
    "            assem_no = 0\n",
    "            assem_size = 0\n",
    "            reactor_type = row[2]\n",
    "            if reactor_type in ['BWR', 'ESBWR']:\n",
    "                assem_no = 732\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 138000 / assem_no\n",
    "            elif reactor_type in ['GCR', 'HWGCR']:  # Need batch number\n",
    "                assem_no = 324\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 114000 / assem_no\n",
    "            elif reactor_type == 'HTGR':  # Need batch number\n",
    "                assem_no = 3944\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 39000 / assem_no\n",
    "            elif reactor_type == 'PHWR':\n",
    "                assem_no = 390\n",
    "                assem_per_batch = assem_no / 45\n",
    "                assem_size = 80000 / assem_no\n",
    "            elif reactor_type == 'VVER':  # Need batch number\n",
    "                assem_no = 312\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 41500 / assem_no\n",
    "            elif reactor_type == 'VVER-1200':  # Need batch number\n",
    "                assem_no = 163\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 80000 / assem_no\n",
    "            else:\n",
    "                assem_no = 241\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 103000 / assem_no\n",
    "\n",
    "            rendered = reactor_template.render(name=name,\n",
    "                                               lifetime=get_lifetime(row),\n",
    "                                               assem_size=assem_size,\n",
    "                                               n_assem_core=assem_no,\n",
    "                                               n_assem_batch=int(\n",
    "                                                   assem_per_batch),\n",
    "                                               power_cap=row[3])\n",
    "            name = out_path + name.replace(' ', '_') + '.xml'\n",
    "            with open(name.lower(), 'w') as output:\n",
    "                output.write(rendered)\n",
    "\n",
    "\n",
    "def get_lifetime(in_list):\n",
    "    \"\"\" Calculates the lifetime of a reactor using first\n",
    "    grid data and shutdown date. Defaults to 720 if these\n",
    "    data are not available\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        single row from PRIS data that contains reactor\n",
    "        information\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lifetime: int\n",
    "        lifetime of reactor\n",
    "    \"\"\"\n",
    "    grid_date = in_list[9]\n",
    "    shutdown_date = in_list[11]\n",
    "    if not shutdown_date.strip():\n",
    "        return 720\n",
    "    else:\n",
    "        n_days_month = 365.0 / 12\n",
    "        delta = (date.parse(shutdown_date) - date.parse(grid_date)).days\n",
    "        return int(delta / n_days_month)\n",
    "\n",
    "\n",
    "out_path = 'cyclus/input/' + region + '/reactors'\n",
    "reactor_template = 'templates/reactors_template.xml'\n",
    "write_reactors(reactor_list, out_path, reactor_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[reactors](cyclus/input/UNITED_STATES/reactors) folder contains individual reactor specifications.\n",
    "\n",
    "## Writing Deployment\n",
    "\n",
    "In order to ensure proper deployment of all reactors during simulation, a function was written to calculate then save deployment information. `build_time`, the number of timesteps taken to deploy the reactors, is calculated using the difference between simulation start date and the reactor first grid date in _CYCLUS_ timesteps (months).\n",
    "\n",
    "### Demonstration \n",
    "__Read PRIS reactor data__\n",
    "\n",
    "`deploy_reactors` function is used for this application. The function imports the PRIS reactor file, produces the folder structure necessary for file output, and calls `get_buildtime` function and `write_deployment` function. `get_buildtime` function parses the deployment dates stored in the PRIS reactor file, and calculates the difference between simulation start date and reactor deployment date in months. Then, the resulting build_time is stored in a dictionary object with the reactor name as key, and the deployed country and deployment month as value. Finally, `write_deployment` function uses the dictionary obtained from `get_buildtime` function to produce deployment specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:53.577118Z",
     "start_time": "2017-11-29T04:01:53.246604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyclus/input/united_states/reactors\n",
      "haddam_neck :  ('United States', 32)\n",
      "san_onofre-1 :  ('United States', 32)\n",
      "oyster_creek :  ('United States', 58)\n",
      "nine_mile_point-1 :  ('United States', 59)\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "def deploy_reactors(in_csv, region, start_year, deployinst_template,\n",
    "                    inclusions_template, reactors_path, deployment_path):\n",
    "    \"\"\" Generates xml files that specifies the reactors that will be included\n",
    "    in a cyclus simulation.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_csv: str\n",
    "        csv file name.\n",
    "    region: str\n",
    "        region name\n",
    "    start_year: int\n",
    "        starting year of simulation\n",
    "    deployinst_template: str\n",
    "        path to deployinst template\n",
    "    inclusions_template: str\n",
    "        path to inclusions template\n",
    "    reactors_path: str\n",
    "        path containing reactor files\n",
    "    deployment_path: str\n",
    "        output path for deployinst xml\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    buildtime_dict: dict\n",
    "        dictionary with key=[name of reactor], and\n",
    "        value=[set of country and buildtime]\n",
    "    \"\"\"\n",
    "    lists = []\n",
    "    if reactors_path[-1] != '/':\n",
    "        reactors_path += '/'\n",
    "    for files in os.listdir(reactors_path):\n",
    "        lists.append(reactors_path + files)\n",
    "    in_data = idata.import_csv(in_csv, ',')\n",
    "    reactor_list = select_region(in_data, region)\n",
    "    buildtime = get_buildtime(reactor_list, start_year, lists)\n",
    "    write_deployment(buildtime, deployment_path, deployinst_template,\n",
    "                     inclusions_template)\n",
    "    return buildtime\n",
    "\n",
    "\n",
    "def get_buildtime(in_list, start_year, path_list):\n",
    "    \"\"\" Obtains information regarding reactors that need to\n",
    "    be deployed and renders the information into a jinja\n",
    "    template\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        list of reactors\n",
    "    start_year: int\n",
    "        starting year of simulation\n",
    "    path_list: list\n",
    "        list of paths to reactor files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    buildtime_dict: dict\n",
    "        dictionary with key=[name of reactor], and\n",
    "        value=[set of country and buildtime]\n",
    "    \"\"\"\n",
    "    buildtime_dict = {}\n",
    "    for row in in_list:\n",
    "        grid_date = date.parse(row[9])\n",
    "        start_date = [grid_date.year, grid_date.month, grid_date.day]\n",
    "        delta = ((start_date[0] - int(start_year)) * 12 +\n",
    "                 (start_date[1]) +\n",
    "                 round(start_date[2] / (365.0 / 12)))\n",
    "        for index, reactor in enumerate(path_list):\n",
    "            ()\n",
    "            name = row[1].replace(' ', '_').lower()\n",
    "            country = row[0]\n",
    "            file_name = (reactor.replace(\n",
    "                os.path.dirname(path_list[index]), '')).replace('/', '')\n",
    "            if (name + '.xml' == file_name):\n",
    "                buildtime_dict.update({name: (country, delta)})\n",
    "    return buildtime_dict\n",
    "\n",
    "\n",
    "def write_deployment(in_dict, out_path, deployinst_template,\n",
    "                     inclusions_template):\n",
    "    \"\"\" Renders jinja template using dictionary of reactor name and buildtime\n",
    "    and outputs an xml file that uses xinclude to include the reactors located\n",
    "    in cyclus_input/reactors.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_dict: dictionary\n",
    "        dictionary with key: reactor name, and value: buildtime.\n",
    "    out_path: str\n",
    "        output path for files\n",
    "    deployinst_template: str\n",
    "        path to deployinst template\n",
    "    inclusions_template: str\n",
    "        path to inclusions template\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    null\n",
    "        generates input files that have deployment and xml inclusions\n",
    "    \"\"\"\n",
    "    if out_path[-1] != '/':\n",
    "        out_path += '/'\n",
    "    pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    deployinst_template = idata.load_template(deployinst_template)\n",
    "    inclusions_template = idata.load_template(inclusions_template)\n",
    "    country_list = {value[0] for value in in_dict.values()}\n",
    "    for nation in country_list:\n",
    "        temp_dict = {}\n",
    "        for reactor in in_dict.keys():\n",
    "            if in_dict[reactor][0].upper() == nation.upper():\n",
    "                temp_dict.update({reactor: in_dict[reactor][1]})\n",
    "        pathlib.Path(out_path + nation.replace(' ', '_') +\n",
    "                     '/').mkdir(parents=True, exist_ok=True)\n",
    "        deployinst = deployinst_template.render(reactors=temp_dict)\n",
    "        with open(out_path + nation.replace(' ', '_') +\n",
    "                  '/deployinst.xml', 'w') as output1:\n",
    "            output1.write(deployinst)\n",
    "    in_dict = {k.lower(): v for k, v in in_dict.items()}\n",
    "    inclusions = inclusions_template.render(reactors=in_dict)\n",
    "    with open(out_path + 'inclusions.xml', 'w') as output2:\n",
    "        output2.write(inclusions)\n",
    "\n",
    "\n",
    "pris_file = 'import_data/reactors_pris_2016.csv'\n",
    "deployinst_tmpl = 'templates/' + region + '/deployinst_template.xml'\n",
    "inclusions_tmpl = 'templates/inclusions_template.xml'\n",
    "reactor_path = 'cyclus/input/' + region + '/reactors'\n",
    "dployment_path = 'cyclus/input/' + region + '/buildtimes'\n",
    "print(reactor_path)\n",
    "buildtime = deploy_reactors(pris_file, region, 1965, deployinst_tmpl,\n",
    "                            inclusions_tmpl, reactor_path, dployment_path)\n",
    "\n",
    "for k in list(buildtime.keys())[:4]:\n",
    "    print(k, ': ', buildtime[k])\n",
    "print('.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[deployinst folder](cyclus/input/UNITED_STATES/buildtimes/) and [inclusions.xml](cyclus/input/UNITED_STATES/buildtimes/inclusions.xml) show the rendered result. \n",
    "\n",
    "`deployinst.xml` contains configurations for _CYCAMORE::DeployInst_ archetype for the agents in the deploy institution and `inclusions.xml` contains xml inclusions so that the final _CYCLUS_ input file references the individual reactor files produced during __Obtaining Deployment Data__ step.\n",
    "\n",
    "## XML inclusion and  Setting XML base for final input file\n",
    "\n",
    "For this investigation, `XInclude` was used to produce modular _CYCLUS_ input files. Rather than a single lengthy input file, the use of xml inclusion allows the creation of _CYCLUS_ input files that contain certain sections such as deployment information, reactor specifications, or even entire regions. This introduces modularity to _CYCLUS_ input files and simulations. To use `XInclude` to reference other files within the input file, an xml base needs to be specified. \n",
    "\n",
    "__XInclude basics__\n",
    "\n",
    "In order to use `XInclude` simply add the `XInclude` namespace to the root element of the xml file that needs to reference another xml file.\n",
    "\n",
    "> xmlns:xi=\"http://www.w3.org/2001/XInclude\"\n",
    "\n",
    "Then, reference the xml file that needs to be added to the base xml file using an `href` tag under the `XInclude` namespace.\n",
    "\n",
    "> `<xi:include href=\"link_to_xml_file_to_be_added.xml\" />`\n",
    "\n",
    "\n",
    "__Example__\n",
    "\n",
    "Below is an example of xml inclusion from the final _CYCLUS_ [input file](cyclus/input/UNITED_STATES.xml) (click to open the full file).\n",
    "\n",
    "```\n",
    "<simulation xml:base=\"/home/gyutae/cyclus/predicting-the-past/cyclus/input/\"\n",
    "  xmlns:xi=\"http://www.w3.org/2001/XInclude\">\n",
    "  <control>\n",
    "    <duration>1020</duration>\n",
    "    <startmonth>1</startmonth>\n",
    "    <startyear>1965</startyear>\n",
    "  </control>\n",
    "  <archetypes>\n",
    "    <spec><lib>cycamore</lib> <name>Enrichment</name> </spec>\n",
    "    <spec><lib>cycamore</lib> <name>Reactor</name>    </spec>\n",
    "    <spec><lib>cycamore</lib> <name>Sink</name>       </spec>\n",
    "    <spec><lib>cycamore</lib> <name>Source</name>     </spec>\n",
    "    <spec><lib>cycamore</lib> <name>Storage</name>    </spec>\n",
    "    <spec><lib>cycamore</lib> <name>DeployInst</name> </spec>\n",
    "    <spec><lib>cycamore</lib> <name>ManagerInst</name></spec>\n",
    "    <spec><lib>agents</lib>   <name>NullRegion</name> </spec>\n",
    "  </archetypes>\n",
    "  <xi:include href=\"UNITED_STATES/buildtimes/inclusions.xml#xpointer(/inclusions/child::*)\"/>\n",
    ".\n",
    ".\n",
    ".\n",
    "```\n",
    "As shown above, `XInclude` namespace was added to the root element: `simulation`. The xml file to be added was declared under the namespace using `xi:include` with the relative link `UNITED_STATES/buildtimes/inclusions.xml#xpointer(/inclusions/child::*)`.\n",
    "\n",
    "__Rationale for setting xml base__\n",
    "\n",
    "One issue that arises with the use of relative path to reference an external document, is that the xml parser (including the one used in _CYCLUS_) does not know where to find the referenced documents. Thus, parsing the final input file from different paths yielded different results and often lead to _unable-to-find-external-entity_ errors. Setting an xml base allows the parser to correctly find the referenced files.\n",
    "\n",
    "__Rendering final input file__\n",
    "\n",
    "Setting an xml base is done by finding the absolute path of the _CYCLUS_ input file, and using `jinja2` to render the absolute path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:53.603247Z",
     "start_time": "2017-11-29T04:01:53.578956Z"
    }
   },
   "outputs": [],
   "source": [
    "def render_cyclus(cyclus_template, region, in_dict, out_path):\n",
    "    \"\"\" Renders final cyclus output file with xml base, and institutions\n",
    "    for each country\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cyclus_template: str\n",
    "        path to cyclus_tempalte\n",
    "    region: str\n",
    "        region chosen for cyclus simulation\n",
    "    in_dict: dictionary\n",
    "        in_dict should be buildtime_dict from get_buildtime function\n",
    "    out_path: str\n",
    "        output path for cyclus input file\n",
    "    output_name:\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    null\n",
    "        writes cyclus input file in out_path\n",
    "    \"\"\"\n",
    "    if out_path[-1] != '/':\n",
    "        out_path += '/'\n",
    "    cyclus_template = idata.load_template(cyclus_template)\n",
    "    country_list = {value[0].replace(' ', '_') for value in in_dict.values()}\n",
    "    rendered = cyclus_template.render(countries=country_list,\n",
    "                                      base_dir=os.path.abspath(out_path) + '/')\n",
    "    with open(out_path + region + '.xml', 'w') as output:\n",
    "        output.write(rendered)\n",
    "\n",
    "\n",
    "cyclus_tmpl = ('templates/' + region + '/' + region + '_template.xml')\n",
    "render_cyclus(cyclus_tmpl, region, buildtime, 'cyclus/input/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[UNITED_STATES.xml](cyclus/input/UNITED_STATES.xml) shows the final _CYCLUS_ input file with all the xml inclusions and xml base.\n",
    "\n",
    "__Running _CYCLUS_ Simulation__\n",
    "\n",
    "Using the final input file above, a _CYCLUS_ simulation is run using the following command on bash. The output of the simulation is uploaded to the ARFC Box for use if _CYCLUS_ is not installed in the device. In such case, skip to _Analysis and Results_ section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:20.342398Z",
     "start_time": "2017-11-29T04:01:53.605202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              :                                                               \n",
      "          .CL:CC CC             _Q     _Q  _Q_Q    _Q    _Q              _Q   \n",
      "        CC;CCCCCCCC:C;         /_\\)   /_\\)/_/\\\\)  /_\\)  /_\\)            /_\\)  \n",
      "        CCCCCCCCCCCCCl       __O|/O___O|/O_OO|/O__O|/O__O|/O____________O|/O__\n",
      "     CCCCCCf     iCCCLCC     /////////////////////////////////////////////////\n",
      "     iCCCt  ;;;;;.  CCCC                                                      \n",
      "    CCCC  ;;;;;;;;;. CClL.                          c                         \n",
      "   CCCC ,;;       ;;: CCCC  ;                   : CCCCi                       \n",
      "    CCC ;;         ;;  CC   ;;:                CCC`   `C;                     \n",
      "  lCCC ;;              CCCC  ;;;:             :CC .;;. C;   ;    :   ;  :;;   \n",
      "  CCCC ;.              CCCC    ;;;,           CC ;    ; Ci  ;    :   ;  :  ;  \n",
      "   iCC :;               CC       ;;;,        ;C ;       CC  ;    :   ; .      \n",
      "  CCCi ;;               CCC        ;;;.      .C ;       tf  ;    :   ;  ;.    \n",
      "  CCC  ;;               CCC          ;;;;;;; fC :       lC  ;    :   ;    ;:  \n",
      "   iCf ;;               CC         :;;:      tC ;       CC  ;    :   ;     ;  \n",
      "  fCCC :;              LCCf      ;;;:         LC :.  ,: C   ;    ;   ; ;   ;  \n",
      "  CCCC  ;;             CCCC    ;;;:           CCi `;;` CC.  ;;;; :;.;.  ; ,;  \n",
      "    CCl ;;             CC    ;;;;              CCC    CCL                     \n",
      "   tCCC  ;;        ;; CCCL  ;;;                  tCCCCC.                      \n",
      "    CCCC  ;;     :;; CCCCf  ;                     ,L                          \n",
      "     lCCC   ;;;;;;  CCCL                                                      \n",
      "     CCCCCC  :;;  fCCCCC                                                      \n",
      "      . CCCC     CCCC .                                                       \n",
      "       .CCCCCCCCCCCCCi                                                        \n",
      "          iCCCCCLCf                                                           \n",
      "           .  C. ,                                                            \n",
      "              :                                                               \n",
      "\n",
      "Status: Cyclus run successful!\n",
      "Output location: ./cyclus/united_states.sqlite\n",
      "Simulation ID: fce12b01-c94e-4973-a2a0-7fa578cdd9ee\n"
     ]
    }
   ],
   "source": [
    "!rm cyclus/united_states.sqlite\n",
    "!cyclus -i ./cyclus/input/united_states.xml -o ./cyclus/united_states.sqlite --warn-limit 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first command removes the previous simulation output file. This is to prevent the final output file from having the results of any previous simulations. The simulation results are stored as an SQLite file [UNITED_STATES.sqlite](cyclus/UNITED_STATES.sqlite). A set of functions were written in python to obtain relevant data from the output file. With python, the results of the queries can be processed to perform meaningful analysis.\n",
    "\n",
    "## Analysis and Results\n",
    "\n",
    "The results for the analysis performed above are shown below. Unfortunately, the only data that was available for comparison at the time of writing was power generated over time published by the Nuclear Energy Institute (NEI) [4]. The NEI publication  contains power generated by US commercial nuclear power plants from 1971 to 2016. A similar plot is generated from the simulation results to compare the power generated and is shown in Figure 10. The plot of power generated from the data published by the NEI is shown in Figure 11.\n",
    "\n",
    "__Connect to SQLite file__\n",
    "\n",
    "To make sqlite queries in python, a cursor, which acts like a pointer to the sqlite file is required. The use of `row_factory` class under `sqlite3` library allows the sqlite table to be indexed by integer values and by case-insensitive row name. `row_factory` produces readable code, and allows easy debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:20.351858Z",
     "start_time": "2017-11-29T04:33:20.344865Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cursor(file_name):\n",
    "    \"\"\" Connects and returns a cursor to an sqlite output file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name: str\n",
    "        name of the sqlite file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sqlite cursor\n",
    "    \"\"\"\n",
    "    con = lite.connect(file_name)\n",
    "    con.row_factory = lite.Row\n",
    "    return con.cursor()\n",
    "\n",
    "\n",
    "cursor = get_cursor('cyclus/united_states.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get simulation start time, duration, and timestep__\n",
    "\n",
    "All analysis results are plotted for a visual representation. `get_timesteps` function is used to obtain simulation start time, and timestep, which are required for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:20.381459Z",
     "start_time": "2017-11-29T04:33:20.353571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  1965 \n",
      "Month:  1 \n",
      "Duration:  1020 \n",
      "Timestep:  [0.000e+00 1.000e+00 2.000e+00 ... 1.017e+03 1.018e+03 1.019e+03]\n"
     ]
    }
   ],
   "source": [
    "def get_timesteps(cur):\n",
    "    \"\"\" Returns simulation start year, month, duration and\n",
    "    timesteps (in numpy linspace).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    init_year: int\n",
    "        start year of simulation\n",
    "    init_month: int\n",
    "        start month of simulation\n",
    "    duration: int\n",
    "        duration of simulation\n",
    "    timestep: list\n",
    "        linspace up to duration\n",
    "    \"\"\"\n",
    "    info = cur.execute('SELECT initialyear, initialmonth, '\n",
    "                       'duration FROM info').fetchone()\n",
    "    init_year = info['initialyear']\n",
    "    init_month = info['initialmonth']\n",
    "    duration = info['duration']\n",
    "    timestep = np.linspace(0, duration - 1, num=duration)\n",
    "\n",
    "    return init_year, init_month, duration, timestep\n",
    "\n",
    "\n",
    "ini_yr, ini_month, dur, timestep = get_timesteps(cursor)\n",
    "print('Year: ', ini_yr, '\\nMonth: ', ini_month, '\\nDuration: ',\n",
    "      dur, '\\nTimestep: ', timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nat_u consumption vs Time__\n",
    "\n",
    "`nat_u_timeseries` function returns a timeseries list of natural uranium sent to the enrichment facility. Unfortunately, this does not represent the amount of natural uranium used in real life as _CYCAMORE::enrichment_ facility does not enrich fuel on a need-basis. Due to current limits in the software, the enrichment facility enriches the same amount of natural uranium at each timestep. When _CYCAMORE::enrichment_ is updated to enrich fuel on a need-basis, this analysis would be more accurate. \n",
    "\n",
    "The `nat_u_timeseries` function makes an sqlite query on the `timeseriesenrichmentfeed` table from the simulation output file and passes the results to `get_timeseries_cum` function. The `get_timeseries_cum` function then calculates the chronological cumulative sum of the natural uranium transferred. The resulting timeseries list is used to plot the cumulative amount of natural uranium used in enrichment over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:22.367848Z",
     "start_time": "2017-11-29T04:33:20.432289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1717: MatplotlibDeprecationWarning: The *left* kwarg to `bar` is deprecated use *x* instead. Support for *left* will be removed in Matplotlib 3.0\n",
      "  return func(ax, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'analysis/results/united_states/Nat_u_consumed vs time.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-41cb59aa2fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m an.stacked_bar_chart(consumption, timestep,\n\u001b[1;32m     63\u001b[0m                      \u001b[0;34m'Time [Yr]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Nat_u_Consumed [MTHM]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                      name, img_out + name, ini_yr)\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_out\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/predicting-the-past/analysis/analysis.py\u001b[0m in \u001b[0;36mstacked_bar_chart\u001b[0;34m(dictionary, timestep, xlabel, ylabel, title, outputname, init_year)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, **kwargs)\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1834\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2267\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2268\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'analysis/results/united_states/Nat_u_consumed vs time.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad43a1ecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def nat_u_timeseries(cur):\n",
    "    \"\"\" Finds natural uranium supply from source\n",
    "        Since currently the source supplies all its capacity,\n",
    "        the timeseriesenrichmentfeed is used.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    get_timeseries: function\n",
    "        calls a function that returns timeseries list of natural U\n",
    "        demand from enrichment [MTHM]\n",
    "    \"\"\"\n",
    "    init_year, init_month, duration, timestep = get_timesteps(cur)\n",
    "    # Get Nat U feed to enrichment from timeseriesenrichmentfeed\n",
    "    feed = cur.execute('SELECT time, sum(value) '\n",
    "                       'FROM timeseriesenrichmentfeed '\n",
    "                       'GROUP BY time').fetchall()\n",
    "\n",
    "    return get_timeseries_cum(feed, duration, True)\n",
    "\n",
    "\n",
    "def get_timeseries_cum(in_list, duration, kg_to_tons):\n",
    "    \"\"\" returns a timeseries list from in_list data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        list of data to be created into timeseries\n",
    "        list[0] = time\n",
    "        list[1] = value, quantity\n",
    "    multiplyby: int\n",
    "        integer to multiply the value in the list by for\n",
    "        unit conversion from kilograms\n",
    "    kg_to_tons: bool\n",
    "        if True, list returned has units of tons\n",
    "        if False, list returned as units of kilograms\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    timeseries of commodities in kg or tons\n",
    "    \"\"\"\n",
    "    value = 0\n",
    "    value_timeseries = []\n",
    "    array = np.array(in_list)\n",
    "    if len(in_list) > 0:\n",
    "        for i in range(0, duration):\n",
    "            value += sum(array[array[:, 0] == i][:, 1])\n",
    "            if kg_to_tons:\n",
    "                value_timeseries.append(value * 0.001)\n",
    "            else:\n",
    "                value_timeseries.append(value)\n",
    "    return value_timeseries\n",
    "\n",
    "\n",
    "img_out = 'analysis/results/' + region + '/'\n",
    "name = 'Nat_u_consumed vs time'\n",
    "consumption = {'Nat_u_consumption': nat_u_timeseries(cursor)}\n",
    "an.stacked_bar_chart(consumption, timestep,\n",
    "                     'Time [Yr]', 'Nat_u_Consumed [MTHM]',\n",
    "                     name, img_out + name, ini_yr)\n",
    "\n",
    "Image(filename=img_out + name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the figure above, natural uranium consumed over the period of the simulation linearly increases. This demonstrates the constant rate of fuel processing performed by the enrichment facility regardless of the demand for fresh fuel. This will hopefully be improved in the future so that the enrichment facilities take the demand for fresh fuel into account.\n",
    "\n",
    "__Amount of fuel into reactors vs. time__\n",
    "\n",
    "A more accurate analysis for fuel consumption is the amount of fuel sent to reactors over time. While the enrichment facility constantly produces fresh fuel, the total amount of fuel sent to reactors changes based on the number and size of the reactors in operation at each timestep. This analysis is performed with `fuel_into_reactors` function. The function makes an sqlite query to the `resources`, `transactions`, and `agententry` table to obtain the amount of fuel sent to reactors throughout the simulation. The resulting data was sent to `get_timeseries_cum` function to obtain a timeseries list of different types of fuel sent to reactors throughout the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:26.964189Z",
     "start_time": "2017-11-29T04:33:22.369736Z"
    }
   },
   "outputs": [],
   "source": [
    "def fuel_into_reactors(cur):\n",
    "    \"\"\" Finds timeseries of mass of fuel received by reactors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    timeseries list of fuel into reactors [tons]\n",
    "    \"\"\"\n",
    "    init_year, init_month, duration, timestep = get_timesteps(cur)\n",
    "    fuel = cur.execute('SELECT time, sum(quantity) FROM transactions '\n",
    "                       'INNER JOIN resources ON '\n",
    "                       'resources.resourceid = transactions.resourceid '\n",
    "                       'INNER JOIN agententry ON '\n",
    "                       'transactions.receiverid = agententry.agentid '\n",
    "                       'WHERE spec LIKE \"%Reactor%\" '\n",
    "                       'GROUP BY time').fetchall()\n",
    "\n",
    "    return get_timeseries_cum(fuel, duration, True)\n",
    "\n",
    "\n",
    "name = 'Fuel into Reactors over Time'\n",
    "to_reactor = {'Fuel_to_reactor': fuel_into_reactors(cursor)}\n",
    "an.stacked_bar_chart(to_reactor, timestep,\n",
    "                     'Time [Yr]', 'Fuel into Reactors [MTHM]',\n",
    "                     name, img_out + name, ini_yr)\n",
    "\n",
    "Image(filename=img_out + name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the figure above, the fuel into reactors over time is not linear and changes with fuel demand of the reactors. This figure reflectes the state of the reactors (whether they were operating or refueling), and the number of reactors operating within the simulation. From the plot, the number of reactors greatly increased around 1990s.\n",
    "\n",
    "__Fuel utilization vs. time__\n",
    "\n",
    "Fuel utilization factor is the ratio of fuel spent to the amount of natural uranium consumed. While, fuel utilization factor is a value of interest, it is inaccurate at the moment of this investigation because the enrichment facilities in _CYCLUS_ does not perform a demand-driven fuel enrichment. Since the amount of natural uranium consumed is not accurate, fuel utilization factor, a derived variable, is also inaccurate. However, the functions used to calculate the fuel utilization factor over time is displayed for future usage. This is performed with `u_util_calc` function, which runs `nat_u_timeseries` function and `fuel_into_reactors` function to obtain the timeseries lists of natural uranium consumed and the amount of fuel consumed. Then, and element-wise division of the two lists were performed to obtain the fuel utilization factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:31.550460Z",
     "start_time": "2017-11-29T04:33:26.965896Z"
    }
   },
   "outputs": [],
   "source": [
    "def u_util_calc(cur):\n",
    "    \"\"\" Returns fuel utilization factor of fuel cycle\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    u_util_timeseries: numpy array\n",
    "        Timeseries of Uranium utilization factor\n",
    "    Prints simulation average Uranium Utilization\n",
    "    \"\"\"\n",
    "    # timeseries of natural uranium\n",
    "    u_supply_timeseries = np.array(nat_u_timeseries(cur))\n",
    "\n",
    "    # timeseries of fuel into reactors\n",
    "    fuel_timeseries = np.array(fuel_into_reactors(cur))\n",
    "\n",
    "    # timeseries of Uranium utilization\n",
    "    u_util_timeseries = np.nan_to_num(fuel_timeseries / u_supply_timeseries)\n",
    "    print('The Average Fuel Utilization Factor is: ')\n",
    "    print(sum(u_util_timeseries) / len(u_util_timeseries))\n",
    "\n",
    "    return u_util_timeseries\n",
    "\n",
    "\n",
    "name = 'Fuel utilization'\n",
    "fuel_util = {'Fuel Utilization Factor': u_util_calc(cursor)}\n",
    "an.stacked_bar_chart(fuel_util, timestep,\n",
    "                     'Time [Yr]', 'Fuel utiliization',\n",
    "                     name, img_out + name, ini_yr)\n",
    "\n",
    "Image(filename=img_out + name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Capacity vs. time__\n",
    "\n",
    "Total capacity over time is obtained using `get_power_dict` function and `capacity_calc` function. The `get_power_dict` function performs four sqlite queries to obtain the following: simulation start date, timesteps, institutions declared in _CYCLUS_, and reactors entry and exit timesteps. The results are sent to `capacity_calc` function, which calculates the timeseries value of the total capacity of the reactors in each institution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:33.907722Z",
     "start_time": "2017-11-29T04:33:31.552012Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_power_dict(cur):\n",
    "    \"\"\" Gets dictionary of power capacity by calling capacity_calc\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    power_dict: dictionary\n",
    "        \"dictionary with key=government, and\n",
    "        value=timeseries list of installed capacity\"\n",
    "    \"\"\"\n",
    "    init_year, init_month, duration, timestep = get_timesteps(cur)\n",
    "    governments = get_inst(cur)\n",
    "\n",
    "    # get power cap values\n",
    "    entry = cur.execute('SELECT max(value), timeseriespower.agentid, '\n",
    "                        'parentid, entertime FROM agententry '\n",
    "                        'INNER JOIN timeseriespower '\n",
    "                        'ON agententry.agentid = timeseriespower.agentid '\n",
    "                        'GROUP BY timeseriespower.agentid').fetchall()\n",
    "\n",
    "    exit_step = cur.execute('SELECT max(value), timeseriespower.agentid, '\n",
    "                            'parentid, exittime FROM agentexit '\n",
    "                            'INNER JOIN timeseriespower '\n",
    "                            'ON agentexit.agentid = timeseriespower.agentid'\n",
    "                            ' INNER JOIN agententry '\n",
    "                            'ON agentexit.agentid = agententry.agentid '\n",
    "                            'GROUP BY timeseriespower.agentid').fetchall()\n",
    "\n",
    "    return capacity_calc(governments, timestep, entry, exit_step)\n",
    "\n",
    "\n",
    "def get_inst(cur):\n",
    "    \"\"\" Returns prototype and agentids of institutions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sqlite query result (list of tuples)\n",
    "    \"\"\"\n",
    "    return cur.execute('SELECT prototype, agentid FROM agententry '\n",
    "                       'WHERE kind = \"Inst\"').fetchall()\n",
    "\n",
    "\n",
    "def capacity_calc(governments, timestep, entry, exit_step):\n",
    "    \"\"\"Adds and subtracts capacity over time for plotting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    governments: list\n",
    "        list of governments (countries)\n",
    "    timestep: np.linspace\n",
    "        list of timestep from 0 to simulation time\n",
    "    entry: list\n",
    "        power_cap, agentid, parentid, entertime\n",
    "        of all entered reactors\n",
    "    exit_step: list\n",
    "        power_cap, agentid, parenitd, exittime\n",
    "        of all decommissioned reactors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    power_dict: dictionary\n",
    "        \"dictionary with key=government, and\n",
    "        value=timeseries list capacity\"\n",
    "    \"\"\"\n",
    "    power_dict = collections.OrderedDict()\n",
    "    for gov in governments:\n",
    "        capacity = []\n",
    "        cap = 0\n",
    "        for t in timestep:\n",
    "            for enter in entry:\n",
    "                if (enter['entertime'] == t and\n",
    "                        enter['parentid'] == gov['agentid']):\n",
    "                    cap += enter['max(value)'] * 0.001\n",
    "            for dec in exit_step:\n",
    "                if (dec['exittime'] == t and\n",
    "                        dec['parentid'] == gov['agentid']):\n",
    "                    cap -= dec['max(value)'] * 0.001\n",
    "            capacity.append(cap)\n",
    "        power_dict[gov['prototype']] = np.asarray(capacity)\n",
    "\n",
    "    return power_dict\n",
    "\n",
    "\n",
    "name = 'Net Capacity vs Time'\n",
    "capacity_dict = get_power_dict(cursor)\n",
    "an.stacked_bar_chart(capacity_dict, timestep,\n",
    "                     'Years', 'Net_Capacity [GWe]',\n",
    "                     name, img_out + name, ini_yr)\n",
    "\n",
    "Image(filename=img_out + name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the figure above, the net capacity greatly increases between 1965 and 1990. The increase in capacity reflects the increase in the number of reactors in operation. Then, the capacity decreases gradually from around 1995. This trend is also shown in the figure of number of reactors over time below.\n",
    "\n",
    "__Number of reactors vs time__\n",
    "\n",
    "A very similar procedure is used to obtain the number of reactors over time. The same four queries made to calculate capacity over time are made to get the number of reactors over time. Then, the result of the queries is passed to `reactor_deployments` function, which calculates the number of reactors operating over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.165844Z",
     "start_time": "2017-11-29T04:33:33.909796Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_deployment_dict(cur):\n",
    "    \"\"\" Gets dictionary of reactors deployed over time\n",
    "    by calling reactor_deployments\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    num_dict: dictionary\n",
    "        \"dictionary with key=government, and\n",
    "        value=timeseries list of number of reactors\"\n",
    "    \"\"\"\n",
    "    init_year, init_month, duration, timestep = get_timesteps(cur)\n",
    "    governments = get_inst(cur)\n",
    "\n",
    "    # get power cap values\n",
    "    entry = cur.execute('SELECT max(value), timeseriespower.agentid, '\n",
    "                        'parentid, entertime FROM agententry '\n",
    "                        'INNER JOIN timeseriespower '\n",
    "                        'ON agententry.agentid = timeseriespower.agentid '\n",
    "                        'GROUP BY timeseriespower.agentid').fetchall()\n",
    "\n",
    "    exit_step = cur.execute('SELECT max(value), timeseriespower.agentid, '\n",
    "                            'parentid, exittime FROM agentexit '\n",
    "                            'INNER JOIN timeseriespower '\n",
    "                            'ON agentexit.agentid = timeseriespower.agentid'\n",
    "                            ' INNER JOIN agententry '\n",
    "                            'ON agentexit.agentid = agententry.agentid '\n",
    "                            'GROUP BY timeseriespower.agentid').fetchall()\n",
    "\n",
    "    return reactor_deployments(governments, timestep, entry, exit_step)\n",
    "\n",
    "\n",
    "def reactor_deployments(governments, timestep, entry, exit_step):\n",
    "    \"\"\"Adds and subtracts number of reactors deployed over time\n",
    "    for plotting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    governments: list\n",
    "        list of governments (countries)\n",
    "    timestep: np.linspace\n",
    "        list of timestep from 0 to simulation time\n",
    "    entry: list\n",
    "        power_cap, agentid, parentid, entertime\n",
    "        of all entered reactors\n",
    "\n",
    "    exit_step: list\n",
    "        power_cap, agentid, parenitd, exittime\n",
    "        of all decommissioned reactors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    deployment: dictionary\n",
    "        \"dictionary with key=government, and\n",
    "        value=timeseries number of reactors\"\n",
    "    \"\"\"\n",
    "    deployment = collections.OrderedDict()\n",
    "    for gov in governments:\n",
    "        num_reactors = []\n",
    "        count = 0\n",
    "        for t in timestep:\n",
    "            for enter in entry:\n",
    "                if (enter['entertime'] == t and\n",
    "                        enter['parentid'] == gov['agentid']):\n",
    "                    count += 1\n",
    "            for dec in exit_step:\n",
    "                if (dec['exittime'] == t and\n",
    "                        dec['parentid'] == gov['agentid']):\n",
    "                    count -= 1\n",
    "            num_reactors.append(count)\n",
    "        deployment[gov['prototype']] = np.asarray(num_reactors)\n",
    "\n",
    "    return deployment\n",
    "\n",
    "\n",
    "name = 'Number of Reactors vs Time'\n",
    "an.stacked_bar_chart(get_deployment_dict(cursor),\n",
    "                     timestep, 'Years', 'Number of Reactors',\n",
    "                     name, img_out + name, ini_yr)\n",
    "\n",
    "Image(filename=img_out + name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Power generated vs. time__\n",
    "\n",
    "The amount of power generated over time is calculated from capacity over time with a few assumptions. Power generated is calculated from capacity with the the following function.\n",
    "\n",
    "$$P(t)=C(t)\\times CF(t)\\times HRPYR$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$P(t) = Power\\ generated\\ over\\ a\\ year\\ [GWh]$$\n",
    "$$C(t) = Capacity\\ over\\ time\\ [GWe]$$\n",
    "$$CF(t)= Capacity\\ factor$$\n",
    "$$HRPYR= Number\\ of\\ hours\\ in\\ a\\ year$$\n",
    "\n",
    "The following assumptions are used for the calculation above.\n",
    "\n",
    "1. Refueling time of all reactors is 1 month.\n",
    "2. Capacity factor is constant throughout the year, and identical for all reactors.\n",
    "3. Reactors generate their full power even during startup and shutdown.\n",
    "\n",
    "Capacity factor data is obtained from the Energy Information Administration (EIA), which has the yearly average capacity factor for reactors in the United States from 1971 to 2017. The capacity factor is assumed constant from 2016 to the end of the simulation and from 1965 to 1971. Capacity factor for each year was stored in a separate [spreadsheet file](analysis/published_data/US/capacity_factor_extrapolated.csv). A set of python functions are used to calculate the power generated over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.175936Z",
     "start_time": "2017-11-29T04:33:36.167782Z"
    }
   },
   "outputs": [],
   "source": [
    "hours_in_year = 24 * 365.25\n",
    "cf_data = import_csv('analysis/published_data/UNITED_STATES/capacity_factor_extrapolated.csv',\n",
    "                     ',')\n",
    "print(*cf_data[:8], sep='\\n')\n",
    "print('.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The capacity factor is assumed to be constant at 48.2% from 1965 to 1971, and at 92.5% from 2017 to 2049. Power generated at each timestep is calculated by performing an element-wise multiplication of  the capacity factor data and the capacity. However, since capacity factor is stored for each year, Assumption 2 is used. A separate function is used to create a list that stores the capacity factor for each timestep of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.326348Z",
     "start_time": "2017-11-29T04:33:36.177653Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cf(in_list):\n",
    "    \"\"\" Creates a list of capacity factor from\n",
    "    the imported csv file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        list containing data stored in a csv file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cf: list\n",
    "        list of capacity factors per month\n",
    "    \"\"\"\n",
    "    cf = []\n",
    "    for row in in_list[1:]:\n",
    "        for i in range(0, 12):\n",
    "            cf.append(float(row[1]) / 100)\n",
    "\n",
    "    return cf\n",
    "\n",
    "name = 'Power Generated'\n",
    "cf = np.asarray(get_cf(cf_data))\n",
    "capacity = capacity_dict['United_States']\n",
    "generated = {\"United_States\": np.multiply(capacity, cf) * hours_in_year}\n",
    "an.stacked_bar_chart(generated, timestep,\n",
    "                     'Years', 'Power Generated [GWh]',\n",
    "                     name, img_out + name, ini_yr)\n",
    "\n",
    "Image(filename=img_out + name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Power generated between 1971 and 2016__\n",
    "\n",
    "The NEI published the amount of power generated by nuclear power plants in the United States between 1971 and 2016 [4]. This information is used to compare the simulation results with the actual data. The data obtained from the previous analysis was used to obtain the power generated between 1971 and 2016 by calculating the starting index and the ending index. The published power generation was plotted for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.327066Z",
     "start_time": "2017-11-29T04:01:52.411Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-094c1df29495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Power Generated 1971~2016'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtimestep_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcf_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m generated_range = {\"United_States\":\n\u001b[1;32m     11\u001b[0m                    generated[\"United_States\"][start_index: end_index]}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cf' is not defined"
     ]
    }
   ],
   "source": [
    "start_year = 1971\n",
    "end_year = 2017\n",
    "start_index = (start_year - 1965) * 12\n",
    "end_index = (end_year - 1965) * 12\n",
    "dura = end_year - start_year\n",
    "\n",
    "name = 'Power Generated 1971~2016'\n",
    "timestep_range = timestep[start_index: end_index]\n",
    "cf_range = cf[start_index: end_index]\n",
    "generated_range = {\"United_States\":\n",
    "                   generated[\"United_States\"][start_index: end_index]}\n",
    "an.stacked_bar_chart(generated_range, timestep_range,\n",
    "                     \"Years\", \"Power Generated [GWh]\",\n",
    "                     name, img_out + name, 1965)\n",
    "\n",
    "Image(filename=img_out + name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.328228Z",
     "start_time": "2017-11-29T04:01:52.414Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'analysis/published_data/united_states/Power Generated NEI.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-71e050de2683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'analysis/published_data/united_states/Power Generated NEI.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0;32m-> 1134\u001b[0;31m                 metadata=metadata)\n\u001b[0m\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'analysis/published_data/united_states/Power Generated NEI.png'"
     ]
    }
   ],
   "source": [
    "Image(filename='analysis/published_data/united_states/Power Generated NEI.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the two plots above,the plot of power generated between 1971 and 2016 from the _CYCLUS_ simulation matches  closely to that published by the NEI. There are a few differences between the two plots. First, the power generated according to _CYCLUS_ is slightly higher overall than that according to NEI. This can be explained from the difference in simulation and real-world refueling times. \n",
    "\n",
    "Due to software limitations of _CYCLUS_, refueling time for reactors can only be entered in integers of month, and stayed constant throughout the lifetime of the plant whereas actual refueling time varies in floating points of month and changes depending on various factors. The _CYCLUS_ simulation used to obtain the power generated over time assumes a refueling period of 1 month. According to the NEI, the average  refueling period for reactors in the United States varies quite significantly. The average refueling period in 1990 was 104 days, a period of over 3 months, and generally decreases to an average refueling period of 35 days, a period  just over 1 month, in 2017. As published by the NEI, the average refueling period of nuclear reactors in the United States is greater than 1 month between 1990 and 2017 [3]. This means that the power generated by the reactors deployed in the _CYCLUS_ simulation will have a greater amount of power generated over a period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "To conclude, _CYCLUS_ performed simulations at an accurate level as shown in the comparison of the power generation plots. However, some improvements in _CYCLUS_ would be benefitial in producing a more accurate simulation: the implementation of an enrichment facility that processes fuel on a need basis. There are other improvements that can be potentially made for this simulation to improve its accuracy.\n",
    "\n",
    "+  Specify actual burnup for reactors\n",
    "    + Currently, the reactors deployed in Cyclus are all deployed with a burnup of 51 GWd/MTHM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] N. Todreas and M. Kazimi, Nuclear systems. Boca Raton, FL: CRC Press, 2012.\n",
    "\n",
    "\n",
    "[2] D. Cacuci, Handbook of nuclear engineering. New York: Springer, 2010.\n",
    "\n",
    "\n",
    "[3] US Nuclear Refueling Outage Days. (n.d.). Retrieved from https://www.nei.org/Knowledge-Center/Nuclear-Statistics/US-Nuclear-Power-Plants/US-Nuclear-Refueling-Outage-Days\n",
    "\n",
    "\n",
    "[4] US Nuclear Generating Statistics. (n.d.). Retrieved from https://www.nei.org/Knowledge-Center/Nuclear-Statistics/US-Nuclear-Power-Plants/US-Nuclear-Generating-Statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
