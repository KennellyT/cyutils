{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the past, United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the United States, 112 commercial reactors have been deployed and operated since 1967. Predicting the past repository uses published data of those commercial reactors and simulates these reactors using _CYCLUS_, an agent-based simulation software, to compare simulation results with the real world statistics such as power generated. These simulations can be used as baseline comparison models for studies that involve simulations modeling the future which include the DOE-NE's study to screen fuel cycle options. Information regarding reactors were obtained from Power Reactor Information System's (PRIS) reactor database. [reactors_pris_2016.csv](import_data/reactors_pris_2016.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Recipes for Simulation\n",
    "\n",
    "First, a input file for _CYCLUS_ that specifies information such as the simulation start year, reactor deployment,  facility deployment, and recipes for fresh and spent nuclear fuel (SNF) was produced. The recipes for fresh and Spent Nuclear Fuel (SNF) were obtained from `vision_recipes.xls` spreadsheet file, which contained composition data for fresh and spent nuclear fuel for uranium oxide (UOX) and mixed oxide (MOX) fuels at different burn ups.\n",
    "\n",
    "Importing raw composition data from `vision_recipes.xls` was performed through a python script and was demonstrated below. Due to limited information about the reactors, all reactors were assumed to operate at a burn up of 51 GWd/MTHM.\n",
    "\n",
    "### Demonstration\n",
    "__Import necessary libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.732663Z",
     "start_time": "2017-11-29T04:01:52.346957Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import dateutil.parser as date\n",
    "import import_fleetcomp as idata\n",
    "import jinja2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import sqlite3 as lite\n",
    "from matplotlib import cm\n",
    "from pyne import nucname as nn\n",
    "from IPython.display import Image\n",
    "\n",
    "sys.path.append('analysis/')\n",
    "import analysis as an\n",
    "\n",
    "region = 'UNITED_STATES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read fuel recipe data__\n",
    "\n",
    "Contents from `vision_recipes.xls` was read and stored in a list object by looping over row in the spreadsheet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.749601Z",
     "start_time": "2017-11-29T04:01:52.734645Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def import_csv(in_csv, delimit):\n",
    "    \"\"\" Imports contents of a comma delimited csv file\n",
    "    to a 2D list.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_csv: str\n",
    "        csv file name.\n",
    "    delimit: str\n",
    "        delimiter of the csv file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_list: list\n",
    "        list with fleetcomp data.\n",
    "    \"\"\"\n",
    "    with open(in_csv, encoding='utf-8') as source:\n",
    "        sourcereader = csv.reader(source, delimiter=delimit)\n",
    "        data_list = []\n",
    "        for row in sourcereader:\n",
    "            data_list.append(row)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "recipes = import_csv('import_data/vision_recipes/uox.csv', ',')\n",
    "print(*recipes[2:6], '.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load template for _CYCLUS_ input file__\n",
    "\n",
    "A jinja template file, which was used to produce the _CYCLUS_ simulation input file was loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.776225Z",
     "start_time": "2017-11-29T04:01:52.751262Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_template(in_template):\n",
    "    \"\"\" Returns a jinja2 template.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_template: str\n",
    "        template file name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_template: jinja template object\n",
    "    \"\"\"\n",
    "    with open(in_template, 'r') as default:\n",
    "        output_template = jinja2.Template(default.read())\n",
    "    return output_template\n",
    "\n",
    "\n",
    "recipe_template = load_template('templates/recipes_template.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select appropriate recipe for a given burnup__\n",
    "\n",
    "The appropriate composition for fresh and spent nuclear fuel was selected with the specified burnup. The composition data was then stored into a dictionary object with isotope as key, and mass fraction composition as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.869248Z",
     "start_time": "2017-11-29T04:01:52.778210Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_composition_fresh(in_list, burnup):\n",
    "    \"\"\" Returns a dictionary of isotope and composition (in mass fraction)\n",
    "    using vision_recipes for fresh UOX\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_list: list\n",
    "        list file containing vision_recipes data.\n",
    "    burnup: int\n",
    "        burnup\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_dict: dictionary\n",
    "        dictionary with key: isotope, and value: composition.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    for i in range(len(in_list)):\n",
    "        if i > 1:\n",
    "            if burnup == 33:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][1])})\n",
    "            elif burnup == 51:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][3])})\n",
    "            else:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][5])})\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def get_composition_spent(in_list, burnup):\n",
    "    \"\"\" Returns a dictionary of isotope and composition (in mass fraction)\n",
    "    using vision_recipes for spent nuclear fuel\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_list: list\n",
    "        list file containing vision_recipes data.\n",
    "    burnup: int\n",
    "        burnup\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_dict: dictionary\n",
    "        dictionary with key: isotope, and value: composition.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    for i in range(len(in_list)):\n",
    "        if i > 1:\n",
    "            if burnup == 33:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][2])})\n",
    "            elif burnup == 51:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][4])})\n",
    "            else:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][6])})\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "fresh = get_composition_fresh(recipes, 51)\n",
    "spent = get_composition_spent(recipes, 51)\n",
    "print('Spent Fuel Composition:')\n",
    "print('ISOTOPE:   Massfrac')\n",
    "for k in list(spent.keys())[:3]:\n",
    "    print(k, ': ', spent[k])\n",
    "print('.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Render recipe template with recipe data__\n",
    "\n",
    "`jinja2` library was used to render recipe data to the previously loaded `recipe_template`. `pyne` converted the isotope name to a _CYCLUS_ readable format. Code then saved the rendered information to an xml file for use with _CYCLUS_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.891348Z",
     "start_time": "2017-11-29T04:01:52.871917Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_recipes(fresh_dict, spent_dict, in_template, burnup, region):\n",
    "    \"\"\" Renders jinja template using fresh and spent fuel composition and\n",
    "    outputs an xml file containing recipe data\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    fresh_dict: dictionary\n",
    "        dictionary with key=isotope, and value=composition for fresh UOX\n",
    "    spent_dict: dictionary\n",
    "        dictionary with key=isotope, and value=composition for spent fuel\n",
    "    in_template: jinja template object\n",
    "        jinja template object to be rendered.\n",
    "    burnup: int\n",
    "        amount of burnup\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    null\n",
    "        generates reactor files for cyclus.\n",
    "    \"\"\"\n",
    "    out_path = 'cyclus/input/' + region + '/recipes/'\n",
    "    pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    rendered = in_template.render(fresh=fresh_dict,\n",
    "                                  spent=spent_dict)\n",
    "    with open(out_path + '/uox_' +\n",
    "              str(burnup) + '.xml', 'w') as output:\n",
    "        output.write(rendered)\n",
    "\n",
    "\n",
    "write_recipes(fresh, spent, recipe_template, 33, region)\n",
    "write_recipes(fresh, spent, recipe_template, 51, region)\n",
    "write_recipes(fresh, spent, recipe_template, 100, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[uox_51.xml](cyclus/input/US/recipes/uox_51.xml) is a sample rendered result that contains fresh and spent nuclear fuel compositions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__recipe template__\n",
    "\n",
    "`jinja2` library was used to produce  _CYCLUS_ input files from templates. The library replaced simulation-specific information, such as the recipe for SNF, to the template file. This allowed end-users to produce _CYCLUS_ simulation inputs that vary in length depending on the data with which it has been rendered. An example is shown below.\n",
    "\n",
    "Recipe template file:\n",
    "\n",
    "```\n",
    "    <recipes>\n",
    "      <recipe>\n",
    "        <name>fresh_uox</name>\n",
    "        <basis>atom</basis>\n",
    "        <nuclide>\n",
    "          <id>922350000</id>\n",
    "          <comp>4.5</comp>\n",
    "        </nuclide>\n",
    "        <nuclide>\n",
    "          <id>922380000</id>\n",
    "          <comp>95.5</comp>\n",
    "        </nuclide>\n",
    "      </recipe>\n",
    "      <recipe>\n",
    "        <name>spent_uox</name>\n",
    "        <basis>atom</basis>\n",
    "        {% for key, value in vision.items() -%}\n",
    "        <nuclide>  <id>{{ key }}</id>  <comp>{{ value }}</comp>  </nuclide>\n",
    "        {% endfor -%}\n",
    "      </recipe>\n",
    "    </recipes>\n",
    "```\n",
    "\n",
    "The template shown above was a recipe template for fresh and spent nuclear fuel. `jinja2` recognized the for-loop in the following lines \n",
    "```\n",
    "    {% for key, value in vision.items() -%}`\n",
    "    <nuclide>  <id>{{ key }}</id>  <comp>{{ value }}</comp>  </nuclide>\n",
    "    {% endfor -%}\n",
    "```\n",
    "and iterated over the composition dictionary to render the isotope and its composition.\n",
    "\n",
    "[uox_51.xml](cyclus/input/US/recipes/uox_51.xml) file shows the rendered result. \n",
    "\n",
    "## Obtaining Deployment Data\n",
    "\n",
    "Reactors specified in [reactors_pris_2016.csv](import_data/reactors_pris_2016.csv), needed to be properly imported. The reactors should be deployed at the correct timesteps for an accurate simulation. The spreadsheet file contained reactor information such as name, deployment date, net capacity, and deployment nation. Obtaining information regarding reactors for _CYCLUS_ was also performed using a set of python functions. The same generic steps were repeated for this demonstration: importing data stored in a delimited text file, and rendering the imported data to a _CYCLUS_ template file.\n",
    "\n",
    "### Demonstration\n",
    "__Read fleetcomp reactor data__\n",
    "\n",
    "The `import_csv` function was also used for this application any other examples below that required data stored in a spreadsheet file to be imported for processing and rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.903340Z",
     "start_time": "2017-11-29T04:01:52.893789Z"
    }
   },
   "outputs": [],
   "source": [
    "pris = import_csv('import_data/reactors_pris_2016.csv', ',')\n",
    "\n",
    "print(*pris[1:6], sep='\\n')\n",
    "print('.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select reactors in the specified region__\n",
    "\n",
    "The PRIS reactor data spreadsheet file contained reactors from all nations. Thus, in order to obtain the reactors deployed in the United States, a separate function was written that selects reactors from the US by searching for a matching nation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:52.958978Z",
     "start_time": "2017-11-29T04:01:52.905315Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_region(in_list, region):\n",
    "    \"\"\" Returns a list of reactors that have a start_date\n",
    "    and are note experimental\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "            imported csv file in list format\n",
    "    region: str\n",
    "            name of the region\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    reactor_list: list\n",
    "            list of reactors from PRIS\n",
    "    \"\"\"\n",
    "    UNITED_STATES = {'UNITED STATES'}\n",
    "    SOUTH_AMERICA = {'ARGENTINA', 'BRAZIL'}\n",
    "    NORTH_AMERICA = {'CANADA', 'MEXICO', 'UNITED STATES'}\n",
    "    EUROPE = {'BELARUS', 'BELGIUM', 'BULGARIA',\n",
    "              'CZECHOSLOVAKIA', 'FINLAND', 'FRANCE',\n",
    "              'GERMANY', 'ITALY', 'NETHERLANDS',\n",
    "              'POLAND', 'ROMANIA', 'RUSSIA',\n",
    "              'SLOVENIA', 'SOVIET UNION', 'SPAIN',\n",
    "              'SWEDEN', 'SWITZERLAND', 'TURKEY',\n",
    "              'UKRAINE', 'UNITED KINGDOM'\n",
    "              }\n",
    "    ASIA = {'BANGLADESH', 'CHINA', 'INDIA',\n",
    "            'IRAN', 'JAPAN', 'KAZAKHSTAN',\n",
    "            'PAKISTAN', 'PHILIPPINES', 'SOUTH KOREA',\n",
    "            'UNITED ARAB EMIRATES', 'VIETNAM'}\n",
    "    AFRICA = {'EGYPT', 'MOROCCO', 'SOUTH AFRICA', 'TUNISIA'}\n",
    "    ALL = SOUTH_AMERICA | NORTH_AMERICA | EUROPE | ASIA | AFRICA | UNITED_STATES\n",
    "    regions = {'SOUTH_AMERICA': SOUTH_AMERICA, 'NORTH_AMERICA': NORTH_AMERICA,\n",
    "               'ASIA': ASIA, 'AFRICA': AFRICA, 'EUROPE': EUROPE, \n",
    "               'UNITED_STATES': UNITED_STATES, 'ALL': ALL}\n",
    "\n",
    "    if region.upper() not in regions.keys():\n",
    "        raise ValueError(region + 'is not a valid region')\n",
    "    reactor_list = []\n",
    "    for row in in_list:\n",
    "        country = row[0]\n",
    "        if country.upper() in regions[region.upper()]:\n",
    "            start_date = row[9]\n",
    "            if start_date.strip():\n",
    "                reactor_list.append(row)\n",
    "    return reactor_list\n",
    "\n",
    "reactor_list = select_region(pris, region)\n",
    "print(*reactor_list[:4], '.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select and render useful reactor information__\n",
    "\n",
    "In this step, the following information was obtained from the PRIS spreadsheet: reactor name, type, deployed nation, and capacity. Other information, such as number of assemblies, assemblies per batch, mass of core, and mass of assembly was obtained from published sources [1], [2]. Then, `write_reactors` function was used to save these information as _CYCLUS_ reactor specifications. The function looped over each row (reactor) and checked the type of reactor and its capacity. It was assumed that reactors with capacity less than 400 MWe were experimental reactors. Then, the function obtained all the raw and derived variables necessary for simulation and rendered the information to the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:53.244829Z",
     "start_time": "2017-11-29T04:01:52.961349Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_reactors(in_list, out_path, reactor_template):\n",
    "    \"\"\" Obtains information regarding reactors\n",
    "    and renders the information into a jinja template\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        list containing PRIS data\n",
    "    out_path: str\n",
    "        output path for reactor files\n",
    "    reactor_template: str\n",
    "        path to reactor template\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    null\n",
    "        writes xml files containing information about a reactor\n",
    "    \"\"\"\n",
    "    if out_path[-1] != '/':\n",
    "        out_path += '/'\n",
    "    pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    reactor_template = idata.load_template(reactor_template)\n",
    "    for row in in_list:\n",
    "        capacity = float(row[3])\n",
    "        if capacity >= 400:\n",
    "            name = row[1].replace(' ', '_')\n",
    "            assem_per_batch = 0\n",
    "            assem_no = 0\n",
    "            assem_size = 0\n",
    "            reactor_type = row[2]\n",
    "            if reactor_type in ['BWR', 'ESBWR']:\n",
    "                assem_no = 732\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 138000 / assem_no\n",
    "            elif reactor_type in ['GCR', 'HWGCR']:  # Need batch number\n",
    "                assem_no = 324\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 114000 / assem_no\n",
    "            elif reactor_type == 'HTGR':  # Need batch number\n",
    "                assem_no = 3944\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 39000 / assem_no\n",
    "            elif reactor_type == 'PHWR':\n",
    "                assem_no = 390\n",
    "                assem_per_batch = assem_no / 45\n",
    "                assem_size = 80000 / assem_no\n",
    "            elif reactor_type == 'VVER':  # Need batch number\n",
    "                assem_no = 312\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 41500 / assem_no\n",
    "            elif reactor_type == 'VVER-1200':  # Need batch number\n",
    "                assem_no = 163\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 80000 / assem_no\n",
    "            else:\n",
    "                assem_no = 241\n",
    "                assem_per_batch = assem_no / 3\n",
    "                assem_size = 103000 / assem_no\n",
    "\n",
    "            rendered = reactor_template.render(name=name,\n",
    "                                               lifetime=get_lifetime(row),\n",
    "                                               assem_size=assem_size,\n",
    "                                               n_assem_core=assem_no,\n",
    "                                               n_assem_batch=int(\n",
    "                                                   assem_per_batch),\n",
    "                                               power_cap=row[3])\n",
    "            with open(out_path + name.replace(' ', '_') + '.xml',\n",
    "                      'w') as output:\n",
    "                output.write(rendered)\n",
    "\n",
    "\n",
    "def get_lifetime(in_list):\n",
    "    \"\"\" Calculates the lifetime of a reactor using first\n",
    "    grid data and shutdown date. Defaults to 720 if these\n",
    "    data are not available\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        single row from PRIS data that contains reactor\n",
    "        information\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lifetime: int\n",
    "        lifetime of reactor\n",
    "    \"\"\"\n",
    "    grid_date = in_list[9]\n",
    "    shutdown_date = in_list[11]\n",
    "    if not shutdown_date.strip():\n",
    "        return 720\n",
    "    else:\n",
    "        n_days_month = 365.0 / 12\n",
    "        delta = (date.parse(shutdown_date) - date.parse(grid_date)).days\n",
    "        return int(delta / n_days_month)\n",
    "\n",
    "\n",
    "out_path = 'cyclus/input/' + region + '/reactors'\n",
    "reactor_template = 'templates/reactors_template.xml'\n",
    "write_reactors(reactor_list, out_path, reactor_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[reactors](cyclus/input/UNITED_STATES/reactors) folder contained _CYCLUS_ input files for all reactors that were deployed in the simulation.\n",
    "\n",
    "## Writing Deployment\n",
    "\n",
    "In order to ensure proper deployment of all reactors during simulation, a separate function was written to calculate then save deployment information. The `build_time`, which was the number of timesteps taken to deploy the reactors, was calculated using the difference between the start date of the simulation and the reactor start date. Since _CYCLUS_ default unit of timestep is a month, the difference was also calculated in months.\n",
    "\n",
    "### Demonstration \n",
    "__Read fleetcomp reactor data__\n",
    "\n",
    "The `deploy_reactors` function was used for this application. The function imported the PRIS reactor file, produced the folder structure necessary for file output, and called `get_buildtime` function and `write_deployment` function. `get_buildtime` function parsed the deployment dates stored in the PRIS reactor file, and calculated the difference between the simulation start date and the reactor deployment date in months. Then, the resulting deployment month was stored in a dictionary object with the reactor name as key. and the deployed country and deployment month as value. Finally, `write_deployment` function uses the dictionary obtained from `get_buildtime` function to write _CYCLUS_ input file that specifies reactor deployment nation and timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:53.577118Z",
     "start_time": "2017-11-29T04:01:53.246604Z"
    }
   },
   "outputs": [],
   "source": [
    "def deploy_reactors(in_csv, region, start_year, deployinst_template,\n",
    "                    inclusions_template, reactors_path, deployment_path):\n",
    "    \"\"\" Generates xml files that specifies the reactors that will be included\n",
    "    in a cyclus simulation.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_csv: str\n",
    "        csv file name.\n",
    "    region: str\n",
    "        region name\n",
    "    start_year: int\n",
    "        starting year of simulation\n",
    "    deployinst_template: str\n",
    "        path to deployinst template\n",
    "    inclusions_template: str\n",
    "        path to inclusions template\n",
    "    reactors_path: str\n",
    "        path containing reactor files\n",
    "    deployment_path: str\n",
    "        output path for deployinst xml\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    buildtime_dict: dict\n",
    "        dictionary with key=[name of reactor], and\n",
    "        value=[set of country and buildtime]\n",
    "    \"\"\"\n",
    "    lists = []\n",
    "    if reactors_path[-1] != '/':\n",
    "        reactors_path += '/'\n",
    "    for files in os.listdir(reactors_path):\n",
    "        lists.append(reactors_path + files)\n",
    "    in_data = idata.import_csv(in_csv, ',')\n",
    "    reactor_list = select_region(in_data, region)\n",
    "    buildtime = get_buildtime(reactor_list, start_year, lists)\n",
    "    write_deployment(buildtime, deployment_path, deployinst_template,\n",
    "                     inclusions_template)\n",
    "    return buildtime\n",
    "\n",
    "\n",
    "def get_buildtime(in_list, start_year, path_list):\n",
    "    \"\"\" Obtains information regarding reactors that need to\n",
    "    be deployed and renders the information into a jinja\n",
    "    template\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        list of reactors\n",
    "    start_year: int\n",
    "        starting year of simulation\n",
    "    path_list: list\n",
    "        list of paths to reactor files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    buildtime_dict: dict\n",
    "        dictionary with key=[name of reactor], and\n",
    "        value=[set of country and buildtime]\n",
    "    \"\"\"\n",
    "    buildtime_dict = {}\n",
    "    for row in in_list:\n",
    "        grid_date = date.parse(row[9])\n",
    "        start_date = [grid_date.year, grid_date.month, grid_date.day]\n",
    "        delta = ((start_date[0] - int(start_year)) * 12 +\n",
    "                 (start_date[1]) +\n",
    "                 round(start_date[2] / (365.0 / 12)))\n",
    "        for index, reactor in enumerate(path_list):\n",
    "            name = row[1].replace(' ', '_')\n",
    "            country = row[0]\n",
    "            file_name = (reactor.replace(\n",
    "                os.path.dirname(path_list[index]), '')).replace('/', '')\n",
    "            if (name + '.xml' == file_name):\n",
    "                buildtime_dict.update({name: (country, delta)})\n",
    "    return buildtime_dict\n",
    "\n",
    "\n",
    "def write_deployment(in_dict, out_path, deployinst_template,\n",
    "                     inclusions_template):\n",
    "    \"\"\" Renders jinja template using dictionary of reactor name and buildtime\n",
    "    and outputs an xml file that uses xinclude to include the reactors located\n",
    "    in cyclus_input/reactors.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_dict: dictionary\n",
    "        dictionary with key: reactor name, and value: buildtime.\n",
    "    out_path: str\n",
    "        output path for files\n",
    "    deployinst_template: str\n",
    "        path to deployinst template\n",
    "    inclusions_template: str\n",
    "        path to inclusions template\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    null\n",
    "        generates input files that have deployment and xml inclusions\n",
    "    \"\"\"\n",
    "    if out_path[-1] != '/':\n",
    "        out_path += '/'\n",
    "    pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    deployinst_template = idata.load_template(deployinst_template)\n",
    "    inclusions_template = idata.load_template(inclusions_template)\n",
    "    country_list = {value[0] for value in in_dict.values()}\n",
    "    for nation in country_list:\n",
    "        temp_dict = {}\n",
    "        for reactor in in_dict.keys():\n",
    "            if in_dict[reactor][0].upper() == nation.upper():\n",
    "                temp_dict.update({reactor: in_dict[reactor][1]})\n",
    "        pathlib.Path(out_path + nation.replace(' ', '_') +\n",
    "                     '/').mkdir(parents=True, exist_ok=True)\n",
    "        deployinst = deployinst_template.render(reactors=temp_dict)\n",
    "        with open(out_path + nation.replace(' ', '_') +\n",
    "                  '/deployinst.xml', 'w') as output1:\n",
    "            output1.write(deployinst)\n",
    "    inclusions = inclusions_template.render(reactors=in_dict)\n",
    "    with open(out_path + 'inclusions.xml', 'w') as output2:\n",
    "        output2.write(inclusions)\n",
    "\n",
    "\n",
    "pris_file = 'import_data/reactors_pris_2016.csv'\n",
    "deployinst_tmpl = 'templates/' + region + '/deployinst_template.xml'\n",
    "inclusions_tmpl = 'templates/inclusions_template.xml'\n",
    "reactor_path = 'cyclus/input/' + region + '/reactors'\n",
    "dployment_path = 'cyclus/input/' + region + '/buildtimes'\n",
    "buildtime = deploy_reactors(pris_file, region, 1965, deployinst_tmpl,\n",
    "                            inclusions_tmpl, reactor_path, dployment_path)\n",
    "\n",
    "for k in list(buildtime.keys())[:4]:\n",
    "    print(k, ': ', buildtime[k])\n",
    "print('.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[deployinst folder](cyclus/input/UNITED_STATES/buildtimes/) and [inclusions.xml](cyclus/input/UNITED_STATES/buildtimes/inclusions.xml) show the rendered result. \n",
    "\n",
    "`deployinst.xml` contained configurations for the _CYCAMORE::DeployInst_ archetype for the reactors in the simulation and `inclusions.xml` contained xml inclusions so that _CYCLUS_ can find and include the reactor files produced during __Obtaining Deployment Data__ step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML inclusion and  Setting XML base for final input file\n",
    "\n",
    "It was important to make sure that an xml base had been specified when xml inclusions through `XInclude` were used. `XInclude` was an easy way to include xml files within other xml files. This introduces modularity to _CYCLUS_ input files and simulations. \n",
    "\n",
    "__XInclude basics__\n",
    "\n",
    "In order to use `XInclude` simply add the `XInclude` namespace to the root element of the xml file that needs to include another xml file.\n",
    "\n",
    "> xmlns:xi=\"http://www.w3.org/2001/XInclude\"\n",
    "\n",
    "Then, reference the xml file that needs to be added to the base xml file using an `href` tag under the `XInclude` namespace.\n",
    "\n",
    "> `<xi:include href=\"link_to_xml_file_to_be_added.xml\" />`\n",
    "\n",
    "\n",
    "__Example__\n",
    "\n",
    "Below is an example of xml inclusion from the final _CYCLUS_ [input file](cyclus/input/UNITED_STATES.xml) (click to open the full file).\n",
    "```\n",
    "<simulation xml:base=\"/home/gyutae/cyclus/predicting-the-past/cyclus/input/\"\n",
    "  xmlns:xi=\"http://www.w3.org/2001/XInclude\">\n",
    "  <control>\n",
    "    <duration>1020</duration>\n",
    "    <startmonth>1</startmonth>\n",
    "    <startyear>1965</startyear>\n",
    "  </control>\n",
    "  <archetypes>\n",
    "    <spec><lib>cycamore</lib> <name>Enrichment</name> </spec>\n",
    "    <spec><lib>cycamore</lib> <name>Reactor</name>    </spec>\n",
    "    <spec><lib>cycamore</lib> <name>Sink</name>       </spec>\n",
    "    <spec><lib>cycamore</lib> <name>Source</name>     </spec>\n",
    "    <spec><lib>cycamore</lib> <name>Storage</name>    </spec>\n",
    "    <spec><lib>cycamore</lib> <name>DeployInst</name> </spec>\n",
    "    <spec><lib>cycamore</lib> <name>ManagerInst</name></spec>\n",
    "    <spec><lib>agents</lib>   <name>NullRegion</name> </spec>\n",
    "  </archetypes>\n",
    "  <xi:include href=\"UNITED_STATES/buildtimes/inclusions.xml#xpointer(/inclusions/child::*)\"/>\n",
    ".\n",
    ".\n",
    ".\n",
    "```\n",
    "As shown above, `XInclude` namespace was added to the root element: `simulation`. The xml file to be added (inclusions.xml) was declared under the namespace using `xi:include` with the relative link `UNITED_STATES/buildtimes/inclusions.xml#xpointer(/inclusions/child::*)`.\n",
    "\n",
    "__Rationale for setting xml base__\n",
    "\n",
    "One issue that arose with the use of relative path to reference an external entity in XInclude, was that the xml parser did not know where to find the referenced documents. Thus, parsing the xml from different directory yielded different results and lead to _unable-to-find-external-entity_ errors. Setting an xml base allowed the parser to correctly find the referenced files.\n",
    "\n",
    "__Rendering final input file__\n",
    "\n",
    "Setting an xml base was done by finding the absolute path of the _CYCLUS_ input file, and using `jinja2` to render the absolute path. Furthermore, in order to specify all the nations that were included for this simulation, `jinja2` was also used to render the different nations as institutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:01:53.603247Z",
     "start_time": "2017-11-29T04:01:53.578956Z"
    }
   },
   "outputs": [],
   "source": [
    "def render_cyclus(cyclus_template, region, in_dict, out_path):\n",
    "    \"\"\" Renders final cyclus output file with xml base, and institutions\n",
    "    for each country\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cyclus_template: str\n",
    "        path to cyclus_tempalte\n",
    "    region: str\n",
    "        region chosen for cyclus simulation\n",
    "    in_dict: dictionary\n",
    "        in_dict should be buildtime_dict from get_buildtime function\n",
    "    out_path: str\n",
    "        output path for cyclus input file\n",
    "    output_name:\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    null\n",
    "        writes cyclus input file in out_path\n",
    "    \"\"\"\n",
    "    if out_path[-1] != '/':\n",
    "        out_path += '/'\n",
    "    cyclus_template = idata.load_template(cyclus_template)\n",
    "    country_list = {value[0].replace(' ', '_') for value in in_dict.values()}\n",
    "    rendered = cyclus_template.render(countries=country_list,\n",
    "                                      base_dir=os.path.abspath(out_path) + '/')\n",
    "    with open(out_path + region + '.xml', 'w') as output:\n",
    "        output.write(rendered)\n",
    "\n",
    "\n",
    "cyclus_tmpl = ('templates/' + region + '/' + region + '_template.xml')\n",
    "render_cyclus(cyclus_tmpl, region, buildtime, 'cyclus/input/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[UNITED_STATES.xml](cyclus/input/UNITED_STATES.xml) shows the final _CYCLUS_ input file with all the xml inclusions and xml base.\n",
    "\n",
    "__Running _CYCLUS_ Simulation__\n",
    "\n",
    "Using the final input file above, a _CYCLUS_ simulation was run using the following command on bash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:20.342398Z",
     "start_time": "2017-11-29T04:01:53.605202Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!rm cyclus/UNITED_STATES.sqlite\n",
    "!cyclus -i ./cyclus/input/UNITED_STATES.xml -o ./cyclus/UNITED_STATES.sqlite --warn-limit 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first command removed the previous output file if it exists. This was to prevent the final output file from having the results of the previous simulation, which was unwanted for this investigation. The output file was named [UNITED_STATES.sqlite](cyclus/UNITED_STATES.sqlite). The results of the simulation were stored as an SQLite file. A set of functions were written in python to make sqlite queries. With python, the results of the queries can be processed to perform a meaningful analysis.\n",
    "\n",
    "## Analysis and Results\n",
    "\n",
    "The results for the analysis performed above were shown below. Unfortunately, the only data that was available for comparison was the power generated over time, which was published by the Nuclear Energy Institute (NEI) [3], [4]. The data published by the NEI contained power generated by US nuclear power plants from 1971 to 2016. Thus, a plot was generated to show the power generated in that time period in Figure 10. The plot of power generated produced from the data published by the NEI was shown in Figure 11.\n",
    "\n",
    "__Connect to SQLite file__\n",
    "\n",
    "To make sqlite queries in _python_, a cursor, which acted like a pointer to the sqlite file was required. The use of `row_factory` class allowed columns in the sqlite table to be indexed by both integer values and by their case-insensitive names. The use of row_factory allowed easy debugging, and prevented confusion that may arise from the change of sqlite queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:20.351858Z",
     "start_time": "2017-11-29T04:33:20.344865Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cursor(file_name):\n",
    "    \"\"\" Connects and returns a cursor to an sqlite output file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name: str\n",
    "        name of the sqlite file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sqlite cursor\n",
    "    \"\"\"\n",
    "    con = lite.connect(file_name)\n",
    "    con.row_factory = lite.Row\n",
    "    return con.cursor()\n",
    "\n",
    "\n",
    "cursor = get_cursor('cyclus/UNITED_STATES.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get simulation start time, duration, and timestep__\n",
    "\n",
    "Since all analysis results were plotted for a visual representation, simulation start time, and timestep were obtained by making an sqlite query using the `get_timesteps` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:20.381459Z",
     "start_time": "2017-11-29T04:33:20.353571Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_timesteps(cur):\n",
    "    \"\"\" Returns simulation start year, month, duration and\n",
    "    timesteps (in numpy linspace).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    init_year: int\n",
    "        start year of simulation\n",
    "    init_month: int\n",
    "        start month of simulation\n",
    "    duration: int\n",
    "        duration of simulation\n",
    "    timestep: list\n",
    "        linspace up to duration\n",
    "    \"\"\"\n",
    "    info = cur.execute('SELECT initialyear, initialmonth, '\n",
    "                       'duration FROM info').fetchone()\n",
    "    init_year = info['initialyear']\n",
    "    init_month = info['initialmonth']\n",
    "    duration = info['duration']\n",
    "    timestep = np.linspace(0, duration - 1, num=duration)\n",
    "\n",
    "    return init_year, init_month, duration, timestep\n",
    "\n",
    "\n",
    "ini_yr, ini_month, dur, timestep = get_timesteps(cursor)\n",
    "print('Year: ', ini_yr, '\\nMonth: ', ini_month, '\\nDuration: ',\n",
    "      dur, '\\nTimestep: ', timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nat_u consumption vs Time__\n",
    "\n",
    "`nat_u_timeseries` function returned a timeseries list of natural uranium sent into the enrichment facility. Unfortunately, this does not represent the amount of natural uranium used in real life as _CYCAMORE::enrichment_ facility did not enrich fuel on a need-basis. Due to current limits in the software, the enrichment facility would always enrich the same amount of natural uranium at each timestep. If _CYCAMORE::enrichment_ were updated to enrich fuel on a need-basis, this analysis would be more accurate. The `nat_u_timeseries` function made an sqlite query on the `timeseriesenrichmentfeed` table from the simulation output file and passed the results to `get_timeseries_cum` function. The `get_timeseries_cum` function calculated the chronological cumulative sum of the natural uranium transferred. The resulting timeseries list was used to plot the cumulative amount of natural uranium used in enrichment over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:20.430567Z",
     "start_time": "2017-11-29T04:33:20.383391Z"
    }
   },
   "outputs": [],
   "source": [
    "def nat_u_timeseries(cur):\n",
    "    \"\"\" Finds natural uranium supply from source\n",
    "        Since currently the source supplies all its capacity,\n",
    "        the timeseriesenrichmentfeed is used.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    get_timeseries: function\n",
    "        calls a function that returns timeseries list of natural U\n",
    "        demand from enrichment [MTHM]\n",
    "    \"\"\"\n",
    "    init_year, init_month, duration, timestep = get_timesteps(cur)\n",
    "    # Get Nat U feed to enrichment from timeseriesenrichmentfeed\n",
    "    feed = cur.execute('SELECT time, sum(value) '\n",
    "                       'FROM timeseriesenrichmentfeed '\n",
    "                       'GROUP BY time').fetchall()\n",
    "\n",
    "    return get_timeseries_cum(feed, duration, True)\n",
    "\n",
    "\n",
    "def get_timeseries_cum(in_list, duration, kg_to_tons):\n",
    "    \"\"\" returns a timeseries list from in_list data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        list of data to be created into timeseries\n",
    "        list[0] = time\n",
    "        list[1] = value, quantity\n",
    "    multiplyby: int\n",
    "        integer to multiply the value in the list by for\n",
    "        unit conversion from kilograms\n",
    "    kg_to_tons: bool\n",
    "        if True, list returned has units of tons\n",
    "        if False, list returned as units of kilograms\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    timeseries of commodities in kg or tons\n",
    "    \"\"\"\n",
    "    value = 0\n",
    "    value_timeseries = []\n",
    "    array = np.array(in_list)\n",
    "    if len(in_list) > 0:\n",
    "        for i in range(0, duration):\n",
    "            value += sum(array[array[:, 0] == i][:, 1])\n",
    "            if kg_to_tons:\n",
    "                value_timeseries.append(value * 0.001)\n",
    "            else:\n",
    "                value_timeseries.append(value)\n",
    "    return value_timeseries\n",
    "\n",
    "\n",
    "consumption = {'Nat_u_consumption': nat_u_timeseries(cursor)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting timeseries was passed onto `stacked_bar_chart` function for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:22.367848Z",
     "start_time": "2017-11-29T04:33:20.432289Z"
    }
   },
   "outputs": [],
   "source": [
    "an.stacked_bar_chart(consumption, timestep,\n",
    "                     'Time [Yr]', 'Nat_u Consumed [MTHM]',\n",
    "                     'Nat_u consumed vs time',\n",
    "                     'analysis/results/UNITED_STATES/Nat_u consumption',\n",
    "                     ini_yr)\n",
    "\n",
    "Image(filename='analysis/results/UNITEDS/Nat_u consumption.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the figure above, the mass of natural uranium consumed over the period of the simulation linearly increased. This indicated that the enrichment facility enriched fuel at a constant rate throughout the simulation, regardless of the demand for fresh fuel. This will hopefully be improved in the future so that the enrichment facilities also take the demand for fresh fuel into account.\n",
    "\n",
    "__Amount of fuel into reactors vs. time__\n",
    "\n",
    "A more accurate analysis for fuel consumption would be the amount of fuel sent to reactors over time. While the enrichment facility constantly produced fresh fuel, the total amount of fuel sent to reactors changed based on the number and size of the reactors in operation at each timestep. This was performed with `fuel_into_reactors` function. The function made an sqlite query to the `resources`, `transactions`, and `agententry` table to obtain the amount of each fuel sent to reactors throughout the simulation. The resulting data was sent to `get_timeseries_cum` function to obtain the timeseries list of different fuels sent to reactors throughout the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:26.964189Z",
     "start_time": "2017-11-29T04:33:22.369736Z"
    }
   },
   "outputs": [],
   "source": [
    "def fuel_into_reactors(cur):\n",
    "    \"\"\" Finds timeseries of mass of fuel received by reactors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    timeseries list of fuel into reactors [tons]\n",
    "    \"\"\"\n",
    "    init_year, init_month, duration, timestep = get_timesteps(cur)\n",
    "    fuel = cur.execute('SELECT time, sum(quantity) FROM transactions '\n",
    "                       'INNER JOIN resources ON '\n",
    "                       'resources.resourceid = transactions.resourceid '\n",
    "                       'INNER JOIN agententry ON '\n",
    "                       'transactions.receiverid = agententry.agentid '\n",
    "                       'WHERE spec LIKE \"%Reactor%\" '\n",
    "                       'GROUP BY time').fetchall()\n",
    "\n",
    "    return get_timeseries_cum(fuel, duration, True)\n",
    "\n",
    "\n",
    "to_reactor = {'Fuel_to_reactor': fuel_into_reactors(cursor)}\n",
    "an.stacked_bar_chart(to_reactor, timestep,\n",
    "                     'Time [Yr]', 'Fuel into Reactors [MTHM]',\n",
    "                     'Fuel to Reactors over Time',\n",
    "                     'analysis/results/US/Fuel to Reactors over Time',\n",
    "                     ini_yr)\n",
    "\n",
    "Image(filename='analysis/results/US/Fuel to Reactors over Time.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the figure above, the amount of fuel into reactors over time is not linear and changes with fuel demand by the reactors. This figure reflects the state of the reactor (whether it is operating or refueling), and the number of reactors. From the plot, it can be seen that the number of reactors greatly increased around 1990s.\n",
    "\n",
    "__Fuel utilization vs. time__\n",
    "\n",
    "Fuel utilization factor is the ratio of fuel spent to the amount of natural uranium consumed. While, fuel utilization factor is a value of interest, it is unfortunately, inaccurate at this moment because the enrichment facilities in _CYCLUS_ does not perform demand-driven fuel enrichment. Since the amount of natural uranium consumed is not accurate due to limitations with software, fuel utilization factor, which is a derived variable, will still be inaccurate. However, the functions used to calculate the fuel utilization factor over time will still be displayed for future usage. This is performed with `u_util_calc` function, which runs `nat_u_timeseries` function and `fuel_into_reactors` function to obtain the timeseries lists of natural uranium consumed and the amount of fuel consumed. Then, and element-wise division of the two lists were performed to obtain the fuel utilization factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:31.550460Z",
     "start_time": "2017-11-29T04:33:26.965896Z"
    }
   },
   "outputs": [],
   "source": [
    "def u_util_calc(cur):\n",
    "    \"\"\" Returns fuel utilization factor of fuel cycle\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    u_util_timeseries: numpy array\n",
    "        Timeseries of Uranium utilization factor\n",
    "    Prints simulation average Uranium Utilization\n",
    "    \"\"\"\n",
    "    # timeseries of natural uranium\n",
    "    u_supply_timeseries = np.array(nat_u_timeseries(cur))\n",
    "\n",
    "    # timeseries of fuel into reactors\n",
    "    fuel_timeseries = np.array(fuel_into_reactors(cur))\n",
    "\n",
    "    # timeseries of Uranium utilization\n",
    "    u_util_timeseries = np.nan_to_num(fuel_timeseries / u_supply_timeseries)\n",
    "    print('The Average Fuel Utilization Factor is: ')\n",
    "    print(sum(u_util_timeseries) / len(u_util_timeseries))\n",
    "\n",
    "    return u_util_timeseries\n",
    "\n",
    "\n",
    "fuel_util = {'Fuel Utilization Factor': u_util_calc(cursor)}\n",
    "an.stacked_bar_chart(fuel_util, timestep,\n",
    "                     'Time [Yr]', 'Fuel utiliization',\n",
    "                     'Fuel utilization',\n",
    "                     'analysis/results/US/Fuel utilization', ini_yr)\n",
    "\n",
    "Image(filename='analysis/results/US/Fuel utilization.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Capacity vs. time__\n",
    "\n",
    "Total capacity over time is obtained using `get_power_dict` function and `capacity_calc` function. The `get_power_dict` function performs four sqlite queries to obtain the following: simulation start date, timesteps, institutions declared in _CYCLUS_, and reactors entry and exit timesteps. The results are sent to `capacity_calc` function, which calculates the timeseries value of the total capacity of the reactors in each institution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:33.907722Z",
     "start_time": "2017-11-29T04:33:31.552012Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_power_dict(cur):\n",
    "    \"\"\" Gets dictionary of power capacity by calling capacity_calc\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    power_dict: dictionary\n",
    "        \"dictionary with key=government, and\n",
    "        value=timeseries list of installed capacity\"\n",
    "    \"\"\"\n",
    "    init_year, init_month, duration, timestep = get_timesteps(cur)\n",
    "    governments = get_inst(cur)\n",
    "\n",
    "    # get power cap values\n",
    "    entry = cur.execute('SELECT max(value), timeseriespower.agentid, '\n",
    "                        'parentid, entertime FROM agententry '\n",
    "                        'INNER JOIN timeseriespower '\n",
    "                        'ON agententry.agentid = timeseriespower.agentid '\n",
    "                        'GROUP BY timeseriespower.agentid').fetchall()\n",
    "\n",
    "    exit_step = cur.execute('SELECT max(value), timeseriespower.agentid, '\n",
    "                            'parentid, exittime FROM agentexit '\n",
    "                            'INNER JOIN timeseriespower '\n",
    "                            'ON agentexit.agentid = timeseriespower.agentid'\n",
    "                            ' INNER JOIN agententry '\n",
    "                            'ON agentexit.agentid = agententry.agentid '\n",
    "                            'GROUP BY timeseriespower.agentid').fetchall()\n",
    "\n",
    "    return capacity_calc(governments, timestep, entry, exit_step)\n",
    "\n",
    "\n",
    "def get_inst(cur):\n",
    "    \"\"\" Returns prototype and agentids of institutions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sqlite query result (list of tuples)\n",
    "    \"\"\"\n",
    "    return cur.execute('SELECT prototype, agentid FROM agententry '\n",
    "                       'WHERE kind = \"Inst\"').fetchall()\n",
    "\n",
    "\n",
    "def capacity_calc(governments, timestep, entry, exit_step):\n",
    "    \"\"\"Adds and subtracts capacity over time for plotting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    governments: list\n",
    "        list of governments (countries)\n",
    "    timestep: np.linspace\n",
    "        list of timestep from 0 to simulation time\n",
    "    entry: list\n",
    "        power_cap, agentid, parentid, entertime\n",
    "        of all entered reactors\n",
    "    exit_step: list\n",
    "        power_cap, agentid, parenitd, exittime\n",
    "        of all decommissioned reactors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    power_dict: dictionary\n",
    "        \"dictionary with key=government, and\n",
    "        value=timeseries list capacity\"\n",
    "    \"\"\"\n",
    "    power_dict = collections.OrderedDict()\n",
    "    for gov in governments:\n",
    "        capacity = []\n",
    "        cap = 0\n",
    "        for t in timestep:\n",
    "            for enter in entry:\n",
    "                if (enter['entertime'] == t and\n",
    "                        enter['parentid'] == gov['agentid']):\n",
    "                    cap += enter['max(value)'] * 0.001\n",
    "            for dec in exit_step:\n",
    "                if (dec['exittime'] == t and\n",
    "                        dec['parentid'] == gov['agentid']):\n",
    "                    cap -= dec['max(value)'] * 0.001\n",
    "            capacity.append(cap)\n",
    "        power_dict[gov['prototype']] = np.asarray(capacity)\n",
    "\n",
    "    return power_dict\n",
    "\n",
    "\n",
    "capacity_dict = get_power_dict(cursor)\n",
    "\n",
    "an.stacked_bar_chart(capacity_dict, timestep,\n",
    "                     'Years', 'Net_Capacity [GWe]',\n",
    "                     'Net Capacity vs Time',\n",
    "                     'analysis/results/US/Capacity vs Time',\n",
    "                     ini_yr)\n",
    "\n",
    "Image(filename='analysis/results/US/Capacity vs Time.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the figure above, the net capacity greatly increases between 1965 and 1990. The increase in capacity reflects the increase in the number of reactors in operation. Then, the capacity decreases gradually from around 1995. This trend is also shown in the figure of number of reactors over time below.\n",
    "\n",
    "__Number of reactors vs time__\n",
    "\n",
    "A very similar procedure is used to obtain the number of reactors over time. The same four queries made to calculate capacity over time were made to get the number of reactors over time. Then, this is passed to `reactor_deployments` functions, which uses a counter to keep track of the number of reactors operating over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.165844Z",
     "start_time": "2017-11-29T04:33:33.909796Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_deployment_dict(cur):\n",
    "    \"\"\" Gets dictionary of reactors deployed over time\n",
    "    by calling reactor_deployments\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cur: sqlite cursor\n",
    "        sqlite cursor\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    num_dict: dictionary\n",
    "        \"dictionary with key=government, and\n",
    "        value=timeseries list of number of reactors\"\n",
    "    \"\"\"\n",
    "    init_year, init_month, duration, timestep = get_timesteps(cur)\n",
    "    governments = get_inst(cur)\n",
    "\n",
    "    # get power cap values\n",
    "    entry = cur.execute('SELECT max(value), timeseriespower.agentid, '\n",
    "                        'parentid, entertime FROM agententry '\n",
    "                        'INNER JOIN timeseriespower '\n",
    "                        'ON agententry.agentid = timeseriespower.agentid '\n",
    "                        'GROUP BY timeseriespower.agentid').fetchall()\n",
    "\n",
    "    exit_step = cur.execute('SELECT max(value), timeseriespower.agentid, '\n",
    "                            'parentid, exittime FROM agentexit '\n",
    "                            'INNER JOIN timeseriespower '\n",
    "                            'ON agentexit.agentid = timeseriespower.agentid'\n",
    "                            ' INNER JOIN agententry '\n",
    "                            'ON agentexit.agentid = agententry.agentid '\n",
    "                            'GROUP BY timeseriespower.agentid').fetchall()\n",
    "\n",
    "    return reactor_deployments(governments, timestep, entry, exit_step)\n",
    "\n",
    "\n",
    "def reactor_deployments(governments, timestep, entry, exit_step):\n",
    "    \"\"\"Adds and subtracts number of reactors deployed over time\n",
    "    for plotting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    governments: list\n",
    "        list of governments (countries)\n",
    "    timestep: np.linspace\n",
    "        list of timestep from 0 to simulation time\n",
    "    entry: list\n",
    "        power_cap, agentid, parentid, entertime\n",
    "        of all entered reactors\n",
    "\n",
    "    exit_step: list\n",
    "        power_cap, agentid, parenitd, exittime\n",
    "        of all decommissioned reactors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    deployment: dictionary\n",
    "        \"dictionary with key=government, and\n",
    "        value=timeseries number of reactors\"\n",
    "    \"\"\"\n",
    "    deployment = collections.OrderedDict()\n",
    "    for gov in governments:\n",
    "        num_reactors = []\n",
    "        count = 0\n",
    "        for t in timestep:\n",
    "            for enter in entry:\n",
    "                if (enter['entertime'] == t and\n",
    "                        enter['parentid'] == gov['agentid']):\n",
    "                    count += 1\n",
    "            for dec in exit_step:\n",
    "                if (dec['exittime'] == t and\n",
    "                        dec['parentid'] == gov['agentid']):\n",
    "                    count -= 1\n",
    "            num_reactors.append(count)\n",
    "        deployment[gov['prototype']] = np.asarray(num_reactors)\n",
    "\n",
    "    return deployment\n",
    "\n",
    "\n",
    "an.stacked_bar_chart(get_deployment_dict(cursor),\n",
    "                     timestep, 'Years',\n",
    "                     'Number of Reactors',\n",
    "                     'Number of Reactors vs Time',\n",
    "                     'analysis/results/US/Number of Reactors vs Time',\n",
    "                     ini_yr)\n",
    "\n",
    "Image(filename='analysis/results/US/Number of Reactors vs Time.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Power generated vs. time__\n",
    "\n",
    "The amount of power generated over time is can be calculated from capacity over time with a few assumptions. Power generated can be calculated from capacity with the using the following function.\n",
    "\n",
    "$$P(t)=C(t)\\times CF(t)\\times HRPYR$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$P(t) = Power\\ generated\\ over\\ a\\ year\\ [GWh]$$\n",
    "$$C(t) = Capacity\\ over\\ time\\ [GWe]$$\n",
    "$$CF(t)= Capacity\\ factor$$\n",
    "$$HRPYR= Number\\ of\\ hours\\ in\\ a\\ year$$\n",
    "\n",
    "The following assumptions were used for the calculation above.\n",
    "\n",
    "1. Refueling time of all reactors is 1 month.\n",
    "2. Capacity factor is constant throughout the year, and equal for all reactors.\n",
    "3. Reactor generates its full power even during startup and shutdown.\n",
    "4. Capacity factor data is obtained from the Energy Information Administration (EIA), which has the average capacity factor for reactors in the United States over a year from 1971 to 2017. The capacity factor is assumed constant from 2016 to the end of the simulation and from 1965 to 1971.\n",
    "\n",
    "Capacity factor for each year is stored in a separate [spreadsheet file](analysis/published_data/US/capacity_factor_extrapolated.csv). A set of python functions were used to calculate the power generated over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.175936Z",
     "start_time": "2017-11-29T04:33:36.167782Z"
    }
   },
   "outputs": [],
   "source": [
    "hours_in_year = 24 * 365.25\n",
    "cf_data = import_csv('analysis/published_data/US/capacity_factor_extrapolated.csv',\n",
    "                     ',')\n",
    "print(*cf_data[:20], sep='\\n')\n",
    "print('.', '.', '.', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption 4 can be seen from `cf_data`. The capacity factor is assumed to be constant at 48.2% from 1965 to 1971, and at 92.5% from 2017 to 2049. Power generated at each timestep is calculated by performing an element-wise multiplication of  the capacity factor data and the capacity. However, since capacity factor is stored for each year, Assumption 2 is used. A separate function is used to create a list that stores the capacity factor for each timestep of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.326348Z",
     "start_time": "2017-11-29T04:33:36.177653Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cf(in_list):\n",
    "    \"\"\" Creates a list of capacity factor from\n",
    "    the imported csv file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list: list\n",
    "        list containing data stored in a csv file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cf: list\n",
    "        list of capacity factors per month\n",
    "    \"\"\"\n",
    "    cf = []\n",
    "    for row in in_list[1:]:\n",
    "        for i in range(0, 12):\n",
    "            cf.append(float(row[1]) / 100)\n",
    "\n",
    "    return cf\n",
    "\n",
    "\n",
    "cf = np.asarray(get_cf(cf_data))\n",
    "capacity = capacity_dict['US']\n",
    "generated = {\"US\": np.multiply(capacity, cf) * hours_in_year}\n",
    "an.stacked_bar_chart(generated, timestep,\n",
    "                     'Years', 'Power Generated [GWh]',\n",
    "                     'Power Generated',\n",
    "                     'analysis/results/US/Power Generated',\n",
    "                     ini_yr)\n",
    "\n",
    "Image(filename='analysis/results/US/Power Generated.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Power generated between 1971 and 2016__\n",
    "\n",
    "The United States Nuclear Energy Institute (NEI) has published the amount of power generated by nuclear power plants in the United States between 1971 and 2016 (US Nuclear Generating Statistics, NEI). This information is used to compare the simulation results with the actual data. Thus, the data obtained from the previous analysis is used to obtain the power generated between 1971 and 2016 by calculating the starting index and the ending index. The actual data is plotted for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.327066Z",
     "start_time": "2017-11-29T04:01:52.411Z"
    }
   },
   "outputs": [],
   "source": [
    "start_year = 1971\n",
    "end_year = 2017\n",
    "start_index = (start_year - 1965) * 12\n",
    "end_index = (end_year - 1965) * 12\n",
    "dura = end_year - start_year\n",
    "\n",
    "timestep_range = timestep[start_index: end_index]\n",
    "cf_range = cf[start_index: end_index]\n",
    "generated_range = {\"US\": generated[\"US\"][start_index: end_index]}\n",
    "\n",
    "an.stacked_bar_chart(generated_range, timestep_range,\n",
    "                     \"Years\", \"Power Generated [GWh]\",\n",
    "                     \"Power Generated\",\n",
    "                     \"analysis/results/US/Power Generated 1971~2016\",\n",
    "                     1965)\n",
    "\n",
    "Image(filename='analysis/results/US/Power Generated 1971~2016.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-29T04:33:36.328228Z",
     "start_time": "2017-11-29T04:01:52.414Z"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename='analysis/published_data/US/Power Generated NEI.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the two plots above,the plot of power generated between 1971 and 2016 from the _CYCLUS_ simulation matches very closely to that published by the NEI. There are a few differences that can be noticed between the two plots. First, the power generated according to _CYCLUS_ is slightly higher than the power generated according to the NEI. This can be explained from the difference in refueling times between simulation and real-world scenarios. Due to software limitations of _CYCLUS_, refueling time for reactors can only be entered in integers of month, and stays constant throughout the lifetime of the plant whereas actual refueling time can vary in floating points of month and changes depending on various factors.\n",
    "\n",
    "_CYCLUS_ simulation used to obtain the power generated over time assumes a refueling period of 1 month. According to the NEI, the average  refueling period for reactors in the United States varies quite significantly. The average refueling period in 1990 was 104 days, a period of over 3 months, and generally decreases to an average refueling period of 35 days, a period of just over 1 month, in 2017. As published by the NEI, the average refueling period of nuclear reactors in the United States has been greater than 1 month between 1990 and 2017. This means that the power generated by the reactors deployed in the _CYCLUS_ simulation would have a greater amount of power generated over a period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "To conclude, _CYCLUS_ has been able to perform simulations at a fairly accurate level as shown in the comparison of the power generation plots. Still, some improvements in _CYCLUS_ would be benefitial: the implementation of an enrichment facility that processes fuel on a need basis. There are other improvements that can be potentially made for this simulation to improve its accuracy.\n",
    "\n",
    "+  Specify actual burnup for reactors\n",
    "    + Currently, the reactors deployed in Cyclus are all deployed with a burnup of 51 GWd/MTHM. \n",
    "    \n",
    "    \n",
    "+  Specify reactor n_assembly_core and batch\n",
    "    + Reactors were deployed in cyclus without the actual number of assemblies per core and batch. The typical values were used for each reactor type (Source needs to be added for the typical values). While the effects of changing these values may not be significant in the outcome of the simulation, specifying such information may benefit the accuracy of the simulation results.\n",
    "    \n",
    "    \n",
    "+  Apply a similar analysis to different regions such as the EU or in the world\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] N. Todreas and M. Kazimi, Nuclear systems. Boca Raton, FL: CRC Press, 2012.\n",
    "\n",
    "\n",
    "[2] D. Cacuci, Handbook of nuclear engineering. New York: Springer, 2010.\n",
    "\n",
    "\n",
    "[3] US Nuclear Refueling Outage Days. (n.d.). Retrieved from https://www.nei.org/Knowledge-Center/Nuclear-Statistics/US-Nuclear-Power-Plants/US-Nuclear-Refueling-Outage-Days\n",
    "\n",
    "\n",
    "[4] US Nuclear Generating Statistics. (n.d.). Retrieved from https://www.nei.org/Knowledge-Center/Nuclear-Statistics/US-Nuclear-Power-Plants/US-Nuclear-Generating-Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
