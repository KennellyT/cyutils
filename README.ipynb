{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the past, United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the United States, 112 commercial reactors have been deployed and operated since 1967. Predicting the past repository uses published data of those commercial reactors and simulates these reactors using _CYCLUS_, an agent-based simulation software, to predict and compare information such as the amount of power generated. Furthermore, these simulations can be used as baseline comparison models for any future studies that involve simulations modelling or predicting the future such is as DOE-NE's study to screen fuel cycle options that aims to identify the potential benefits and challegnes of fuel cycle options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Recipes for Simulation\n",
    "\n",
    "First, a input file for _CYCLUS_ that specifies information such as the simulation start year, reactor deployment year, facility deployment, and recipes for fresh and spent nuclear fuel (SNF) need to be produced. The recipes for fresh and SNF were obtained from `vision_recipes.xls` spreadsheet file. The file contains composition data for fresh and spent nuclear fuel for uranium oxide (UOX) and mixed oxide (MOX) fuels for different burn ups.\n",
    "\n",
    "Importing raw composition data from `vision_recipes.xls` was performed through python and will be demonstrated below. Due to limited information regarding the reactors, all reactors were assumed to operate at a burn up of 51 GWd/MTHM.\n",
    "\n",
    "### Demonstration\n",
    "__Import necessary libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import jinja2\n",
    "import pyne.nucname as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read fuel recipe data__\n",
    "\n",
    "Opens and saves contents from `vision_recipes.xls` files to a list by looping over each cell in the spreadsheet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv(in_csv, delimit):\n",
    "    \"\"\" Imports contents of a comma delimited csv file\n",
    "    to a 2D list.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_csv: str\n",
    "        csv file name.\n",
    "    delimit: str\n",
    "        delimiter of the csv file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_list: list\n",
    "        list with fleetcomp data.\n",
    "    \"\"\"\n",
    "    with open(in_csv, encoding='utf-8') as source:\n",
    "        sourcereader = csv.reader(source, delimiter=delimit)\n",
    "        data_list = []\n",
    "        for row in sourcereader:\n",
    "            data_list.append(row)\n",
    "    return data_list\n",
    "\n",
    "recipes = import_csv('import_data/vision_recipes/uox.csv', ',')\n",
    "recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load template for _CYCLUS_ input file__\n",
    "\n",
    "Imports the template file used to render recipe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_template(in_template):\n",
    "    \"\"\" Returns a jinja2 template.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_template: str\n",
    "        template file name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_template: jinja template object\n",
    "    \"\"\"\n",
    "    with open(in_template, 'r') as default:\n",
    "        output_template = jinja2.Template(default.read())\n",
    "    return output_template\n",
    "\n",
    "recipe_template = load_template('templates/US/recipes_template.xml')\n",
    "recipe_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select appropriate recipe for a given burnup__\n",
    "\n",
    "Uses the imported list and a given amount of burnup to select the appropriate composition data. The data is then stored into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_composition(in_list, burnup):\n",
    "    \"\"\" Returns a dictionary of reactor name and build_time (in months)\n",
    "    using the fleetcomp list for reactors specified in *args.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_list: list\n",
    "        list file containing fleetcomp data.\n",
    "    *args: str\n",
    "        path and name of reactors that will be added to cyclus simulation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_dict: dictionary\n",
    "        dictionary with key: isotope, and value: composition.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    for i in range(len(in_list)):\n",
    "        if i > 1:\n",
    "            if burnup == 33:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][2])})\n",
    "            elif burnup == 51:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][4])})\n",
    "            else:\n",
    "                data_dict.update({nn.id(in_list[i][0]):\n",
    "                                  float(in_list[i][6])})\n",
    "    return data_dict\n",
    "\n",
    "composition = get_composition(recipes, 51)\n",
    "composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Render recipe template with recipe data__\n",
    "\n",
    "Uses `jinja2` to render recipe data stored in a dictionary to `recipe_template` and `pyne` to convert isotope name for _CYCLUS_. Saves rendered object file to an xml file for use with _CYCLUS_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_recipes(in_dict, in_template, burnup):\n",
    "    \"\"\" Renders jinja template using data from in_list and\n",
    "    outputs an xml file for a single reactor.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    data_dict: dictionary\n",
    "        dictionary with key: isotope, and value: composition.\n",
    "    in_template: jinja template object\n",
    "        jinja template object to be rendered.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    null\n",
    "        generates reactor files for cyclus.\n",
    "    \"\"\"\n",
    "    rendered = in_template.render(vision=in_dict)\n",
    "    with open('cyclus/input/US/recipes/uox_' + str(burnup) +\n",
    "              '.xml', 'w') as output:\n",
    "        output.write(rendered)\n",
    "\n",
    "write_recipes(composition, recipe_template, 51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[uox_51.xml](cyclus/input/US/recipes/uox_51.xml) file shows the rendered result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__recipe template__\n",
    "\n",
    "`jinja2` allows iteration over iterable objects such as lists, sets, and dictionaries. This allows end-users to produce rendered output files that vary in length depending on the data that it has been rendered with. An example is shown below.\n",
    "\n",
    "Recipe template file:\n",
    "\n",
    "```\n",
    "<recipes>\n",
    "  <recipe>\n",
    "    <name>fresh_uox</name>\n",
    "    <basis>atom</basis>\n",
    "    <nuclide>\n",
    "      <id>922350000</id>\n",
    "      <comp>4.5</comp>\n",
    "    </nuclide>\n",
    "    <nuclide>\n",
    "      <id>922380000</id>\n",
    "      <comp>95.5</comp>\n",
    "    </nuclide>\n",
    "  </recipe>\n",
    "  <recipe>\n",
    "    <name>spent_uox</name>\n",
    "    <basis>atom</basis>\n",
    "    {% for key, value in vision.items() -%}\n",
    "    <nuclide>  <id>{{ key }}</id>  <comp>{{ value }}</comp>  </nuclide>\n",
    "    {% endfor -%}\n",
    "  </recipe>\n",
    "</recipes>\n",
    "```\n",
    "\n",
    "The template is a template for an xml file that follows the _CYCLUS_ xml schema. `jinja2` recognizes the for-loop in the following lines \n",
    "```\n",
    "{% for key, value in vision.items() -%}`\n",
    "<nuclide>  <id>{{ key }}</id>  <comp>{{ value }}</comp>  </nuclide>\n",
    "{% endfor -%}\n",
    "```\n",
    "and iterates over the composition dictionary to render the isotope and its composition.\n",
    "\n",
    "[uox_51.xml](cyclus/input/US/recipes/uox_51.xml) file shows the rendered result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Deployment Data\n",
    "\n",
    "Reactors specified in [US fleetcomp](import_data/fleetcomp/US_Fleet.txt) spreadsheet, need to be properly imported and deployed at the correct timesteps for a successful simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "### Adding Deployment Data\n",
    "#### Files Used\n",
    "\n",
    "+ ##### Input\n",
    "    *  [US_Fleet.txt](import_data/fleetcomp/US_Fleet.txt) - fleetcomp data of US nuclear power plants.\n",
    "    *  [deployinst_template.xml](templates/deployinst_template.xml) - an XML template that provides the structure for _CYCAMORE_ _DEPLOYISNT_ archetype.\n",
    "    *  [inclusions_template.xml](templates/inclusions_template.xml) - an XML file used to declare all XML inclusion links using xinclude. The referenced files contain information regarding reactors such as core mass, power_cap, etc.\n",
    "    *  [112 Reactor files](cyclus/input/reactors) - 112 files containing information regarding reactors deployed in the United States since 1965.\n",
    "\n",
    "+ ##### Script\n",
    "    *  [import_data.py](import_data.py) - a script that is used to import, process and produce recipes for UOX, and SNF.\n",
    "\n",
    "+ ##### Output\n",
    "    *  [deployinst.xml](cyclus/input/buildtimes/deployinst.xml) - an XML file containing deployment information regarding all reactors that are deployed in the _CYCAMORE DEPLOYINST_ archetype.\n",
    "    *  [inclusions.xml](cyclus/input/buildtimes/inclusions.xml) - an XML file that has xinclude links for _CYCLUS_ input file. The referenced files include information regarding reactors.\n",
    "\n",
    "    This process involves two main steps. Calculating deployment time steps for _CYCAMORE DEPLOYISNT_ archetype, and using `jinja` templates to make two XML files: `deployinst` and `inclusions`. By default, the `import_data` script deploys all reactors contained in the US fleetcomp.\n",
    "    \n",
    "    The buildtimes for all reactors were obtained from the `US_Fleet` text file, which contains the deployment date of the reactors. By comparing and finding the difference between the simulation start date and the reactor deployment date, an appropriate build_time was obtained in units of months. Note that since _CYCAMORE DEPLOYINST_ archetype only accepts integer values for reactor build time, the final difference is casted into an integer value within python. In addition, the following assumptions were made in calculating the difference between simulation start date and reactor deployment date,\n",
    "\n",
    "+ ###### Assumptions\n",
    "    * Differences were calculated individually in YEARS, MONTHS, and DAYS\n",
    "    * The difference in DAYS were converted into MONTHS by using the ratio between the number of days in a year (365 DAYS) and the number of months in year (12 MONTHS) so that each month is assumed to have the same number of days.\n",
    "    * The difference in YEARS were converted into MONTHS by using the number of months in a year (12 MONTHS).\n",
    "    \n",
    "    Then a dictionary of the reactor name (key), and build time (value) was passed to a function that renders the information contained in the dictionary to the output files listed above.\n",
    "\n",
    "### Setting XML base for final input file\n",
    "#### Files Used\n",
    "\n",
    "+ ##### Input\n",
    "    *  [predicting_the_past_template.xml](templates/predicting_the_past_template.xml) - an XML template including a _CYCLUS_ input file.\n",
    "\n",
    "+ ##### Script\n",
    "    *  [import_data.py](import_data.py) - a script that is used to import, process and produce recipes for UOX, and SNF\n",
    "\n",
    "+ ##### Output\n",
    "    *  [predicting_the_past.xml](cyclus/input/predicting_the_past.xml) - Final input file for _CYCLUS_\n",
    "\n",
    "    One of the issues associated with using xinclude to include external XML files referenced by a relative path is that the path is sensitive the directory to which it is called. For instance, if the final _CYCLUS_ input file was called in any other directory than `cyclus/input`, then XML parsers, such as the one used in _CYCLUS_ is unable to find the files specified in the input file. To fix this issue, a `jinja` template of the _CYCLUS_ input file is created and rendered with the absolute directory of the _CYCLUS_ input file. This allows XML parsers to recognize the relative paths used in xinclude as paths relative to that specified as `xml base`. This is also done in the `import_data` script.\n",
    "\n",
    "### Running Cyclus simulation\n",
    "#### Files Used\n",
    "\n",
    "+ ##### Input\n",
    "    *  [predicting_the_past.xml](cyclus/input/predicting_the_past.xml) - Final input file for _CYCLUS_\n",
    "\n",
    "+ ##### Output\n",
    "    *  [US.sqlite](cyclus/US.sqlite) - A _CYCLUS_ simulation result file.\n",
    "\n",
    "    _CYCLUS_ simulation is run. This is often performed in a separate ipython notebook ([Analysis.ipynb](analysis/Analysis.ipynb)). To view the output file from a fresh copy of the Github repository, please open the ipython notebook above to run the _CYCLUS_ simulation with the input file above.\n",
    "    \n",
    "### Analyzing Output\n",
    "#### Files Used\n",
    "\n",
    "+ ##### Input\n",
    "    *  [US.sqlite](cyclus/US.sqlite) - A _CYCLUS_ simulation result file.\n",
    "    \n",
    "+ ##### Script\n",
    "    *  [analysis.py](analysis/analysis.py) - A python script containing functions required for the analysis of _CYCLUS_ output file\n",
    "    \n",
    "    The analysis for the _CYCLUS_ simulation is done using the `analysis` script and is outlined in a separate ipython notebook ([Analysis.ipynb](analysis/Analysis.ipynb)). A number of different data was obtained from the _CYCLUS_ output file. The following data was obtained from the _CYCLUS_ output file. \n",
    "    \n",
    "    \n",
    "        1. Amount of natural uranium consumed over time\n",
    "        2. Amount of fuel into all reactors over time\n",
    "        3. Fuel utilization over time\n",
    "        4. Capacity over time\n",
    "        5. Number of reactors over time\n",
    "        6. Separative Work Unit (SWU) over time\n",
    "        7. Amount of Spend Nuclear Fuel (SNF) in Sink over time\n",
    "        8. Amount of tailings over time\n",
    "        9. Power generated over time\n",
    "        \n",
    "    1. Amount of natural uranium consumed over time\n",
    "    \n",
    "    This uses `nat_u_timeseries` function within `analysis` script that makes a simple sqlite query to the `timeseries enrichmentfeed` table in the _CYCLUS_ output file. The query requests the the amount of uranium sent to any enrichment facilities at each time step and passes those values into `get_timeseries_cum` function. \n",
    "    \n",
    "    The `get_timeseries_cum` function accepts a list that contains time (in index 0) and value (in index 1), and calculates the cumulative sum of those values in chronological order. This new list is then returned to plot the values in a graph, which is shown in the Results section.\n",
    "    \n",
    "    2. Amount of fuel into all reactors over time\n",
    "    \n",
    "    This uses `fuel_into_reactors` function within `analysis` script. The `fuel_into_reactors` function makes an sqlite query from `transactions`, `resources`, and `agententry` table to search for the amount of fuel sent to any reactors at each time step. The function utilizes `INNER JOIN` capabilities of sqlite3 to merge the three tables above. It searches for matching resources in transactions done betweem enricment facilities and reactors to find records of fuel sent to reactors. The results of this query is passed to the `get_timeseries_cum` function to obtain a cumulative list of fuel sent to reactors over time, which is then used to plot the values into a graph.\n",
    "    \n",
    "    3. Fuel utilization over time\n",
    "    \n",
    "    This uses `u_util_calc` function within `analysis` script that calls `nat_u_timeseries` and `fuel_into_reactors` functions and saves the resulting timeseries list into a numpy array. Then the function performs an element-by-element division of fuel_timeseries by uranium_supply_timeseries. The resulting array contains the timeseries list of fuel utilization factor. The resulting timeseries list is used for plotting.\n",
    "    \n",
    "    4. Capacity over time\n",
    "    \n",
    "    This uses `get_power_dict` function within `analysis` script. This function makes two function calls and two sqlite queries. First, `get_timesteps` function, and `get_inst` function are called. The former returns the starting year, month, duration, and a numpy linspace that contains the timesteps of the simulation. The latter returns the prototype and the agent ids of any institutions specified in the _CYCLUS_ simulation. The first sqlite query obtains the agentid, entrytime, power, and parentid. The second sqlite query obtains the agentid, exittime, power, and parentid. Then, all information is passed into `capacity_calc` function. The `capacity_calc` function collects these input parameters, then loops through each time step, and calculates the cumulative capacity of all the reactors for each _CYCLUS_ institution.\n",
    "    \n",
    "    5. Number of reactors over time\n",
    "    \n",
    "    This uses `get_deployment_dict` function within `analysis` script. This function is very similar to `get_power_dict` in that the same function calls and queries are made. The results of these function calls and queries are passed to `reactor_deployments`, which instead of producing a timeseries of capacity, produces a timeseries of reactors deployed.\n",
    "    \n",
    "    6. SWU over time\n",
    "    \n",
    "    This uses `get_swu_dict` function within `analysis` script. The function first gets the agent_id of all enrichment facilities in the simulation. Then, it loops through the list of enrichment agent_ids and performs the following: make an sqlite query to obtain the SWU at each time step for an enrichment facility, passes the result of the query to `get_timeseries_cum` to obtain the timeseries of the cumulative SWU, and stores the timeseries list into a dictionary value with the enrichment facilities agent id as key. This dictionary is used to produce a graph of SWU over time for each enrichment facility.\n",
    "    \n",
    "    7. Amount of SNF in sink over time\n",
    "    \n",
    "    This uses `facility_commodity_flux` function within `analysis` script. The function takes in a sqlite cursor, list of agent_ids, list of commodities, and a boolean value to specify influx or out flux. It loops through the list of commodities, and makes an sqlite query to obtain the amount of commodity transferred at each time step. Then, it passes the results of the query to `get_timeseries_cum` to obtain the timeseries list of each commodity. The lists are then stored as dictionary values with the commodity as key.\n",
    "    \n",
    "    8. Amount of tailings over time\n",
    "    \n",
    "    This also uses `facility_commodity_flux` function within `analysis` script. First the function makes an sqlite query to obtain the agent id for a  Low Level Waste (LLW) sink facility and stores the agent ids in a list. Then it calls `facility_commodity_flux` with tails as the commodity parameter. The resulting dictionary was used to plot the timeseries of tailings over time.\n",
    "    \n",
    "    9. Power generated over time\n",
    "    \n",
    "    This uses `get_power_dict` function, and capacity factor information published by the NEI (US Nuclear Generating Statistics). The power generated is calculated with the following assumptions.\n",
    "   \n",
    "        1.  Capacity factor is constant for every month in a year\n",
    "        2.  For years where the capacity factor data is missing, the capacity factor is assumed constant\n",
    "        3.  Refueling time for all reactors is 1 month\n",
    "        \n",
    "    The power generated is calculated by calculating the element-by-element product of capacity factor and overall capacity then converting units from giga-watts (GW) to giga-watt-hours (GWh). The resulting dictionary is used to plot the power generated over time. \n",
    "    \n",
    "    A similar plot of power generated was produced from the data published by the NEI (US Nuclear Generating Statistics). The data contains the mount of power generated each year in mega-watt-hours (MWh). The plot was generated using one of the plotting functions in the `analysis` script. Since ,the plotting function requires power generated at each month, rather than year, the power generated was assumed to be constant throughout the months in a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The results for the analysis performed above are shown below. Unfortunately, the only data that is available for comparison is the power generated over time. NEI has also published this on their website (US Nuclear Generating Statistics). The data published by the NEI was saved in a spreadsheet so that it can be plotted for comparison. Since the data contains power generated by US nuclear power plants from 1971 to 2016, a new plot was generated to only show the power generated between that period in Figure 10. The plot of power generated produced from the data published by the NEI is shown in Figure 11.\n",
    "\n",
    "1. Amount of natural uranium consumed over time\n",
    "![Nat_u vs. Time](analysis/results/US/Nat_u consumption.png)\n",
    "2. Amount of fuel into all reactors over time\n",
    "![Fuel to Reactors vs. Time](analysis/results/US/Fuel to Reactors over Time.png)\n",
    "3. Fuel utilization over time\n",
    "![Fuel utilization vs. Time](analysis/results/US/Fuel utilization.png)\n",
    "4. Capacity over time\n",
    "![Capacity vs. Time](analysis/results/US/Capacity vs Time.png)\n",
    "5. Number of reactors over time\n",
    "![Number of Reactors vs. Time](analysis/results/US/Number of Reactors vs Time.png)\n",
    "6. Separative Work Unit (SWU) over time\n",
    "![SWU vs. Time](analysis/results/US/SWU vs Time.png)\n",
    "7. Amount of Spend Nuclear Fuel (SNF) in Sink over time\n",
    "![Spent_UOX in Sink vs. Time](analysis/results/US/Spent_UOX in Repository.png)\n",
    "8. Amount of tailings over time\n",
    "![Tailings vs. Time](analysis/results/US/Tailings in Sink.png)\n",
    "9. Power generated over time\n",
    "![Power Generated vs. Time](analysis/results/US/Power Generated.png)\n",
    "10. Power generated between 1971~2016\n",
    "![Power Generated (1971~2016)](analysis/results/US/Power Generated 1971~2016.png)\n",
    "11. Power generated between 1971~2016 (US Nuclear Generating Statistics, NEI)\n",
    "![Power Generated NEI (1971~2016)](analysis/published_data/US/Power Generated NEI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "As shown in Figure 10 and 11, the plot of the amount of power generated between 1971 and 2016 from the _CYCLUS_ simulation matches very closely to that published by the NEI. There are a few differences that can be noticed between the two plots. First, the power generated according to _CYCLUS_ is slightly higher than the power generated according to the NEI. This can be explained from the difference in refueling times between simulation and real-world scenarios. Due to software limitations of _CYCLUS_, refueling time for reactors can only be entered in integers of month, and stays constant throughout the lifetime of the plant whereas actual refueling time can vary in floating points of month and changes depending on various factors.\n",
    "\n",
    "_CYCLUS_ simulation used to generate Figure 10 assumes a refueling period of 1 month. According to the NEI, the average  refueling period for reactors in the United States varies quite significantly. The average refueling period in 1990 was 104 days, a period of over 3 months, and generally decreases to an average refueling period of 35 days, a period of just over 1 month, in 2017. As published by the NEI, the average refueling period of nuclear reactors in the United States has been greater than 1 month between 1990 and 2017. This means that the power generated by the reactors deployed in the _CYCLUS_ simulation would have a greater amount of power generated over a period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Goals\n",
    "+  Specify actual burnup for reactors\n",
    "    + Currently, the reactors deployed in Cyclus are all deployed with a burnup of 51 GWd/MTHM. \n",
    "    \n",
    "    \n",
    "+  Specify reactor n_assembly_core and batch\n",
    "    + Reactors were deployed in cyclus without the actual number of assemblies per core and batch. The typical values were used for each reactor type (Source needs to be added for the typical values). While the effects of changing these values may not be significant in the outcome of the simulation, specifying such information may benefit the accuracy of the simulation results.\n",
    "    \n",
    "    \n",
    "+  Apply a similar analysis to different regions such as the EU or in the world\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "*  US Nuclear Generating Statistics. (n.d.). Retrieved from https://www.nei.org/Knowledge-Center/Nuclear-Statistics/US-Nuclear-Power-Plants/US-Nuclear-Generating-Statistics\n",
    "\n",
    "\n",
    "*  US Nuclear Refueling Outage Days. (n.d.). Retrieved from https://www.nei.org/Knowledge-Center/Nuclear-Statistics/US-Nuclear-Power-Plants/US-Nuclear-Refueling-Outage-Days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information\n",
    "\n",
    "### XInclude\n",
    "\n",
    "_CYCLUS_'s XML parser has the capabilities of parsing xinclude. To include an XML file (i.e. a.xml) into another XML (i.e. b.xml) file, add xinclude in the XML namespace by adding the following to the root tag of `b.xml`:\n",
    "\n",
    "> xmlns:xi=\"http://www.w3.org/2001/XInclude\"\n",
    "\n",
    "Then, reference the XML file to be added (`a.xml`) into the appropriate level with the following line:\n",
    "\n",
    "> `<xi:include href=\"[path_to_a.xml/a.xml]\" />`\n",
    "\n",
    "The path specified above can be absolute or relative. However, if it is relative, the path where the XML parsing is called needs to be the same as the path of the file that has all the XML inclusions. One way to avoid this issue with xinclude is to add an `xml:base` tag that contains the absolute path of the file that has all the XML inclusions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
